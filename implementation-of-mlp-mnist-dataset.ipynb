{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pony1013/implementation-of-mlp-no-tf-keras-pytorch?scriptVersionId=162020069\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"913ad931","metadata":{"papermill":{"duration":0.003145,"end_time":"2024-02-07T08:02:27.901322","exception":false,"start_time":"2024-02-07T08:02:27.898177","status":"completed"},"tags":[]},"source":["This is a simple 4 layer MLP of the MNIST dataset classification, where sigmoid are used as activation functions of all layers.\n","\n","All 42000 images belong to 10 classes.\n","\n","# 1. Preprocessing Stage\n","\n","- Before we put those images into the NN, we have to do some preprocessings to reduce overfitting and boost the accuracy.\n","\n","- X_train = X_train/255.0 is used to normalize the train_data\n","\n","\n","\n","\n","# 2. FeedForward Propagation\n","\n","Output of the neuron follows :\n","\n","$\\sum = wx + b$\n","\n","$o = sigmoid(\\sum)$\n","\n","Suppose $w_1,w_2,w_3,b_1,b_2,b_3$ are the weights and biases of layer 2-4 respectively, we have the ouput:\n","\n","$o_1 = sigmoid(\\sum w_1x + b_1)$\n","\n","$o_2 = sigmoid(\\sum w_2o_1 +b_2)$\n","\n","$o_3 = sigmoid(\\sum w_3o_2 +b_3)$\n","\n","# 3. BackwardPropagation\n","\n","This algorithm uses gradient descent method as optimization method.\n","\n","Suppose $\\delta_1,\\delta_2,\\delta_3$ be the **responsibility** of the error in layer 2-4 respectively, and E is the total loss of the model, we have for the output layer:\n","\n","$\\delta_3 = \\frac{\\partial E}{\\partial w_3} = \\frac{\\partial E}{\\partial o_3} \\cdot \\frac{\\partial o_3}{\\partial \\sum_3} = E\\cdot o_3(1-o_3) = E\\cdot \\sigma(\\sum_3)(1-\\sigma(\\sum_3))$\n","\n","**Thus, the weight correction for weights in layer 3-4 is :**\n","\n","$\\varDelta w_3 = \\gamma \\cdot o_3 \\cdot \\delta_3$ where $\\gamma$ is the learning rate.\n","\n","For the layer 2 and 3, Suppose $o_1,o_2$ be the output of layer 2 and 3 respectively:\n","\n","$\\delta_2 = \\frac{\\partial E}{\\partial w_2} = \\frac{\\partial E}{\\partial o_2} \\cdot \\frac{\\partial o_2}{\\partial \\sum_2} = o_2(1-o_2) \\cdot \\sum \\delta_3 \\cdot w_2$ \n","\n","The weight correction of layer 2-3 weights are followed by :\n","\n","$\\varDelta w_2 = \\gamma \\cdot o_2 \\cdot \\delta_2$\n","\n","For the weights in layer 1-2, the weights correction follows the same formula as layer 2-3 as they are all inner neurons.\n","\n","# 4. Activation Functions\n","\n","1. ReLu\n","- Relu is the most popular activation function in machine learning, it is defined as :\n","\n","$ReLu(x) = x$ for x>0\n","\n","$ReLu(x) = 0$ for x<0\n","\n","Relu is famous of it's simplifcity of it's derivative function, the derivative of ReLu is :\n","\n","$ReLU'(x) = 0$ for x<0\n","\n","$ReLU'(x) = 1$ for x>0\n","\n","  2. Softmax\n","    - Softmax is another popular activation function, it can helps transform the output into probability, the softmax function is defined as :\n","\n"," $softmax(z)_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}$\n","\n","  3. Sigmoid\n","\n","   - Sigmoid is a type of activation function which has a S shape, in this program, the sigmoid function we used in this model is :\n","\n","$Sigmoid(x) = \\frac{1}{1+e^{-x}}$\n"]},{"cell_type":"code","execution_count":1,"id":"b357284a","metadata":{"execution":{"iopub.execute_input":"2024-02-07T08:02:27.909184Z","iopub.status.busy":"2024-02-07T08:02:27.908759Z","iopub.status.idle":"2024-02-07T12:57:52.821264Z","shell.execute_reply":"2024-02-07T12:57:52.820116Z"},"papermill":{"duration":17724.974821,"end_time":"2024-02-07T12:57:52.879055","exception":false,"start_time":"2024-02-07T08:02:27.904234","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/600 Accuracy: 6.154761904761904%\n","Epoch 2/600 Accuracy: 9.035714285714286%\n","Epoch 3/600 Accuracy: 9.85%\n","Epoch 4/600 Accuracy: 9.85%\n","Epoch 5/600 Accuracy: 20.854761904761904%\n","Epoch 6/600 Accuracy: 21.883333333333333%\n","Epoch 7/600 Accuracy: 16.173809523809524%\n","Epoch 8/600 Accuracy: 28.15952380952381%\n","Epoch 9/600 Accuracy: 34.82380952380952%\n","Epoch 10/600 Accuracy: 58.397619047619045%\n","Epoch 11/600 Accuracy: 63.121428571428574%\n","Epoch 12/600 Accuracy: 65.32142857142857%\n","Epoch 13/600 Accuracy: 72.89761904761905%\n","Epoch 14/600 Accuracy: 77.45238095238095%\n","Epoch 15/600 Accuracy: 77.72142857142858%\n","Epoch 16/600 Accuracy: 80.45476190476191%\n","Epoch 17/600 Accuracy: 78.91904761904762%\n","Epoch 18/600 Accuracy: 81.6%\n","Epoch 19/600 Accuracy: 79.31666666666666%\n","Epoch 20/600 Accuracy: 82.2952380952381%\n","Epoch 21/600 Accuracy: 79.91904761904762%\n","Epoch 22/600 Accuracy: 82.45%\n","Epoch 23/600 Accuracy: 79.60952380952381%\n","Epoch 24/600 Accuracy: 79.01904761904763%\n","Epoch 25/600 Accuracy: 74.86666666666667%\n","Epoch 26/600 Accuracy: 75.45476190476191%\n","Epoch 27/600 Accuracy: 73.3547619047619%\n","Epoch 28/600 Accuracy: 78.9452380952381%\n","Epoch 29/600 Accuracy: 79.52142857142857%\n","Epoch 30/600 Accuracy: 78.4452380952381%\n","Epoch 31/600 Accuracy: 82.08095238095238%\n","Epoch 32/600 Accuracy: 80.8952380952381%\n","Epoch 33/600 Accuracy: 84.09285714285714%\n","Epoch 34/600 Accuracy: 79.49047619047619%\n","Epoch 35/600 Accuracy: 85.3%\n","Epoch 36/600 Accuracy: 83.98809523809524%\n","Epoch 37/600 Accuracy: 85.48809523809524%\n","Epoch 38/600 Accuracy: 82.01428571428572%\n","Epoch 39/600 Accuracy: 85.57857142857142%\n","Epoch 40/600 Accuracy: 82.65238095238095%\n","Epoch 41/600 Accuracy: 85.03095238095239%\n","Epoch 42/600 Accuracy: 82.1952380952381%\n","Epoch 43/600 Accuracy: 82.09761904761905%\n","Epoch 44/600 Accuracy: 79.06666666666666%\n","Epoch 45/600 Accuracy: 78.38571428571429%\n","Epoch 46/600 Accuracy: 83.11428571428571%\n","Epoch 47/600 Accuracy: 87.92142857142858%\n","Epoch 48/600 Accuracy: 88.19285714285714%\n","Epoch 49/600 Accuracy: 88.28095238095239%\n","Epoch 50/600 Accuracy: 88.24761904761905%\n","Epoch 51/600 Accuracy: 88.42619047619048%\n","Epoch 52/600 Accuracy: 88.24285714285715%\n","Epoch 53/600 Accuracy: 88.44047619047619%\n","Epoch 54/600 Accuracy: 88.14285714285714%\n","Epoch 55/600 Accuracy: 88.2452380952381%\n","Epoch 56/600 Accuracy: 87.53571428571428%\n","Epoch 57/600 Accuracy: 87.70476190476191%\n","Epoch 58/600 Accuracy: 85.9452380952381%\n","Epoch 59/600 Accuracy: 86.06190476190476%\n","Epoch 60/600 Accuracy: 80.45476190476191%\n","Epoch 61/600 Accuracy: 81.89047619047619%\n","Epoch 62/600 Accuracy: 70.61666666666667%\n","Epoch 63/600 Accuracy: 77.74047619047619%\n","Epoch 64/600 Accuracy: 73.64047619047619%\n","Epoch 65/600 Accuracy: 78.3547619047619%\n","Epoch 66/600 Accuracy: 78.18809523809523%\n","Epoch 67/600 Accuracy: 83.17857142857143%\n","Epoch 68/600 Accuracy: 78.80952380952381%\n","Epoch 69/600 Accuracy: 84.7452380952381%\n","Epoch 70/600 Accuracy: 74.62142857142857%\n","Epoch 71/600 Accuracy: 82.95476190476191%\n","Epoch 72/600 Accuracy: 74.7547619047619%\n","Epoch 73/600 Accuracy: 81.19761904761906%\n","Epoch 74/600 Accuracy: 80.93809523809524%\n","Epoch 75/600 Accuracy: 85.39285714285715%\n","Epoch 76/600 Accuracy: 84.78809523809524%\n","Epoch 77/600 Accuracy: 85.87142857142858%\n","Epoch 78/600 Accuracy: 86.09523809523809%\n","Epoch 79/600 Accuracy: 85.11428571428571%\n","Epoch 80/600 Accuracy: 85.62380952380953%\n","Epoch 81/600 Accuracy: 84.29523809523809%\n","Epoch 82/600 Accuracy: 85.0904761904762%\n","Epoch 83/600 Accuracy: 84.35714285714285%\n","Epoch 84/600 Accuracy: 84.62857142857143%\n","Epoch 85/600 Accuracy: 84.32380952380953%\n","Epoch 86/600 Accuracy: 84.78571428571429%\n","Epoch 87/600 Accuracy: 84.87142857142858%\n","Epoch 88/600 Accuracy: 85.6547619047619%\n","Epoch 89/600 Accuracy: 85.8452380952381%\n","Epoch 90/600 Accuracy: 86.78095238095239%\n","Epoch 91/600 Accuracy: 86.88809523809525%\n","Epoch 92/600 Accuracy: 87.45714285714286%\n","Epoch 93/600 Accuracy: 87.27619047619048%\n","Epoch 94/600 Accuracy: 86.63095238095238%\n","Epoch 95/600 Accuracy: 85.77619047619048%\n","Epoch 96/600 Accuracy: 82.66666666666667%\n","Epoch 97/600 Accuracy: 79.8404761904762%\n","Epoch 98/600 Accuracy: 79.29047619047618%\n","Epoch 99/600 Accuracy: 83.12142857142857%\n","Epoch 100/600 Accuracy: 87.18333333333334%\n","Epoch 101/600 Accuracy: 87.86428571428571%\n","Epoch 102/600 Accuracy: 88.11666666666666%\n","Epoch 103/600 Accuracy: 88.8047619047619%\n","Epoch 104/600 Accuracy: 88.47857142857143%\n","Epoch 105/600 Accuracy: 88.97857142857143%\n","Epoch 106/600 Accuracy: 88.43095238095238%\n","Epoch 107/600 Accuracy: 89.0047619047619%\n","Epoch 108/600 Accuracy: 87.9857142857143%\n","Epoch 109/600 Accuracy: 88.62380952380953%\n","Epoch 110/600 Accuracy: 86.90476190476191%\n","Epoch 111/600 Accuracy: 87.97857142857143%\n","Epoch 112/600 Accuracy: 85.36190476190477%\n","Epoch 113/600 Accuracy: 87.0547619047619%\n","Epoch 114/600 Accuracy: 84.38333333333333%\n","Epoch 115/600 Accuracy: 84.1047619047619%\n","Epoch 116/600 Accuracy: 80.70714285714286%\n","Epoch 117/600 Accuracy: 80.35714285714286%\n","Epoch 118/600 Accuracy: 83.85952380952381%\n","Epoch 119/600 Accuracy: 87.96666666666667%\n","Epoch 120/600 Accuracy: 86.60952380952381%\n","Epoch 121/600 Accuracy: 87.29285714285714%\n","Epoch 122/600 Accuracy: 84.66666666666667%\n","Epoch 123/600 Accuracy: 85.45%\n","Epoch 124/600 Accuracy: 81.05952380952381%\n","Epoch 125/600 Accuracy: 83.21428571428572%\n","Epoch 126/600 Accuracy: 78.79047619047618%\n","Epoch 127/600 Accuracy: 75.66190476190476%\n","Epoch 128/600 Accuracy: 68.04285714285714%\n","Epoch 129/600 Accuracy: 69.28095238095237%\n","Epoch 130/600 Accuracy: 59.43571428571428%\n","Epoch 131/600 Accuracy: 79.38095238095238%\n","Epoch 132/600 Accuracy: 80.42142857142856%\n","Epoch 133/600 Accuracy: 85.33095238095238%\n","Epoch 134/600 Accuracy: 87.29523809523809%\n","Epoch 135/600 Accuracy: 87.76904761904763%\n","Epoch 136/600 Accuracy: 88.03571428571428%\n","Epoch 137/600 Accuracy: 87.2547619047619%\n","Epoch 138/600 Accuracy: 87.3452380952381%\n","Epoch 139/600 Accuracy: 85.37142857142858%\n","Epoch 140/600 Accuracy: 86.00238095238095%\n","Epoch 141/600 Accuracy: 83.42142857142856%\n","Epoch 142/600 Accuracy: 86.18095238095238%\n","Epoch 143/600 Accuracy: 85.7452380952381%\n","Epoch 144/600 Accuracy: 86.5047619047619%\n","Epoch 145/600 Accuracy: 86.0142857142857%\n","Epoch 146/600 Accuracy: 86.90952380952382%\n","Epoch 147/600 Accuracy: 86.96190476190476%\n","Epoch 148/600 Accuracy: 87.6%\n","Epoch 149/600 Accuracy: 87.91666666666667%\n","Epoch 150/600 Accuracy: 88.46666666666667%\n","Epoch 151/600 Accuracy: 88.5047619047619%\n","Epoch 152/600 Accuracy: 88.93571428571428%\n","Epoch 153/600 Accuracy: 88.55714285714285%\n","Epoch 154/600 Accuracy: 88.95714285714286%\n","Epoch 155/600 Accuracy: 88.08571428571429%\n","Epoch 156/600 Accuracy: 88.27619047619048%\n","Epoch 157/600 Accuracy: 86.6595238095238%\n","Epoch 158/600 Accuracy: 86.89761904761905%\n","Epoch 159/600 Accuracy: 84.45238095238096%\n","Epoch 160/600 Accuracy: 85.11428571428571%\n","Epoch 161/600 Accuracy: 82.83809523809524%\n","Epoch 162/600 Accuracy: 82.59761904761905%\n","Epoch 163/600 Accuracy: 82.69285714285715%\n","Epoch 164/600 Accuracy: 84.8452380952381%\n","Epoch 165/600 Accuracy: 84.23333333333333%\n","Epoch 166/600 Accuracy: 88.03809523809524%\n","Epoch 167/600 Accuracy: 86.82380952380953%\n","Epoch 168/600 Accuracy: 89.36190476190477%\n","Epoch 169/600 Accuracy: 88.43571428571428%\n","Epoch 170/600 Accuracy: 89.6952380952381%\n","Epoch 171/600 Accuracy: 89.16190476190476%\n","Epoch 172/600 Accuracy: 89.87857142857143%\n","Epoch 173/600 Accuracy: 89.70238095238095%\n","Epoch 174/600 Accuracy: 90.04761904761904%\n","Epoch 175/600 Accuracy: 89.86666666666666%\n","Epoch 176/600 Accuracy: 90.13809523809525%\n","Epoch 177/600 Accuracy: 90.02857142857142%\n","Epoch 178/600 Accuracy: 90.17857142857143%\n","Epoch 179/600 Accuracy: 90.05714285714286%\n","Epoch 180/600 Accuracy: 90.11666666666667%\n","Epoch 181/600 Accuracy: 89.90714285714286%\n","Epoch 182/600 Accuracy: 89.8404761904762%\n","Epoch 183/600 Accuracy: 89.49047619047619%\n","Epoch 184/600 Accuracy: 88.96428571428572%\n","Epoch 185/600 Accuracy: 88.03571428571428%\n","Epoch 186/600 Accuracy: 84.87380952380953%\n","Epoch 187/600 Accuracy: 82.20476190476191%\n","Epoch 188/600 Accuracy: 78.75952380952381%\n","Epoch 189/600 Accuracy: 79.62857142857143%\n","Epoch 190/600 Accuracy: 81.39761904761905%\n","Epoch 191/600 Accuracy: 66.29761904761905%\n","Epoch 192/600 Accuracy: 53.70952380952381%\n","Epoch 193/600 Accuracy: 54.12619047619047%\n","Epoch 194/600 Accuracy: 53.40238095238096%\n","Epoch 195/600 Accuracy: 55.528571428571425%\n","Epoch 196/600 Accuracy: 67.7404761904762%\n","Epoch 197/600 Accuracy: 84.26190476190476%\n","Epoch 198/600 Accuracy: 89.64761904761905%\n","Epoch 199/600 Accuracy: 89.95476190476191%\n","Epoch 200/600 Accuracy: 90.21428571428571%\n","Epoch 201/600 Accuracy: 90.22142857142858%\n","Epoch 202/600 Accuracy: 90.31904761904762%\n","Epoch 203/600 Accuracy: 90.32857142857142%\n","Epoch 204/600 Accuracy: 90.40714285714286%\n","Epoch 205/600 Accuracy: 90.4452380952381%\n","Epoch 206/600 Accuracy: 90.45238095238095%\n","Epoch 207/600 Accuracy: 90.48809523809524%\n","Epoch 208/600 Accuracy: 90.4952380952381%\n","Epoch 209/600 Accuracy: 90.51904761904763%\n","Epoch 210/600 Accuracy: 90.54761904761904%\n","Epoch 211/600 Accuracy: 90.5547619047619%\n","Epoch 212/600 Accuracy: 90.55952380952381%\n","Epoch 213/600 Accuracy: 90.5404761904762%\n","Epoch 214/600 Accuracy: 90.61428571428571%\n","Epoch 215/600 Accuracy: 90.49047619047619%\n","Epoch 216/600 Accuracy: 90.5952380952381%\n","Epoch 217/600 Accuracy: 90.4095238095238%\n","Epoch 218/600 Accuracy: 90.51904761904763%\n","Epoch 219/600 Accuracy: 90.20714285714286%\n","Epoch 220/600 Accuracy: 90.36428571428571%\n","Epoch 221/600 Accuracy: 89.82857142857142%\n","Epoch 222/600 Accuracy: 89.95%\n","Epoch 223/600 Accuracy: 88.71428571428571%\n","Epoch 224/600 Accuracy: 88.8952380952381%\n","Epoch 225/600 Accuracy: 85.75714285714285%\n","Epoch 226/600 Accuracy: 87.4857142857143%\n","Epoch 227/600 Accuracy: 82.86428571428571%\n","Epoch 228/600 Accuracy: 87.50714285714287%\n","Epoch 229/600 Accuracy: 84.95714285714286%\n","Epoch 230/600 Accuracy: 87.21666666666667%\n","Epoch 231/600 Accuracy: 85.11904761904762%\n","Epoch 232/600 Accuracy: 86.76904761904763%\n","Epoch 233/600 Accuracy: 84.95%\n","Epoch 234/600 Accuracy: 84.43333333333334%\n","Epoch 235/600 Accuracy: 81.05238095238096%\n","Epoch 236/600 Accuracy: 78.83095238095238%\n","Epoch 237/600 Accuracy: 84.99285714285715%\n","Epoch 238/600 Accuracy: 88.94999999999999%\n","Epoch 239/600 Accuracy: 89.18809523809523%\n","Epoch 240/600 Accuracy: 89.62142857142858%\n","Epoch 241/600 Accuracy: 89.08809523809524%\n","Epoch 242/600 Accuracy: 89.40476190476191%\n","Epoch 243/600 Accuracy: 88.21428571428571%\n","Epoch 244/600 Accuracy: 88.01190476190476%\n","Epoch 245/600 Accuracy: 83.8952380952381%\n","Epoch 246/600 Accuracy: 86.52380952380952%\n","Epoch 247/600 Accuracy: 82.31428571428572%\n","Epoch 248/600 Accuracy: 87.50238095238096%\n","Epoch 249/600 Accuracy: 85.98095238095237%\n","Epoch 250/600 Accuracy: 86.77857142857142%\n","Epoch 251/600 Accuracy: 83.7357142857143%\n","Epoch 252/600 Accuracy: 85.83095238095238%\n","Epoch 253/600 Accuracy: 82.81428571428572%\n","Epoch 254/600 Accuracy: 85.57857142857142%\n","Epoch 255/600 Accuracy: 83.66904761904762%\n","Epoch 256/600 Accuracy: 85.86904761904762%\n","Epoch 257/600 Accuracy: 85.14761904761905%\n","Epoch 258/600 Accuracy: 86.74761904761905%\n","Epoch 259/600 Accuracy: 87.05714285714285%\n","Epoch 260/600 Accuracy: 87.82619047619048%\n","Epoch 261/600 Accuracy: 88.17619047619047%\n","Epoch 262/600 Accuracy: 87.19285714285714%\n","Epoch 263/600 Accuracy: 85.87857142857143%\n","Epoch 264/600 Accuracy: 81.44047619047619%\n","Epoch 265/600 Accuracy: 89.68333333333334%\n","Epoch 266/600 Accuracy: 90.26666666666667%\n","Epoch 267/600 Accuracy: 90.5404761904762%\n","Epoch 268/600 Accuracy: 90.55952380952381%\n","Epoch 269/600 Accuracy: 90.69047619047619%\n","Epoch 270/600 Accuracy: 90.70238095238096%\n","Epoch 271/600 Accuracy: 90.77619047619048%\n","Epoch 272/600 Accuracy: 90.81666666666666%\n","Epoch 273/600 Accuracy: 90.79761904761905%\n","Epoch 274/600 Accuracy: 90.87142857142857%\n","Epoch 275/600 Accuracy: 90.84761904761905%\n","Epoch 276/600 Accuracy: 90.88809523809523%\n","Epoch 277/600 Accuracy: 90.8404761904762%\n","Epoch 278/600 Accuracy: 90.9095238095238%\n","Epoch 279/600 Accuracy: 90.86666666666666%\n","Epoch 280/600 Accuracy: 90.87380952380953%\n","Epoch 281/600 Accuracy: 90.75714285714285%\n","Epoch 282/600 Accuracy: 90.86904761904762%\n","Epoch 283/600 Accuracy: 90.60952380952381%\n","Epoch 284/600 Accuracy: 90.80238095238096%\n","Epoch 285/600 Accuracy: 90.44285714285715%\n","Epoch 286/600 Accuracy: 90.60714285714285%\n","Epoch 287/600 Accuracy: 90.02380952380953%\n","Epoch 288/600 Accuracy: 90.11428571428571%\n","Epoch 289/600 Accuracy: 88.71904761904761%\n","Epoch 290/600 Accuracy: 88.85714285714286%\n","Epoch 291/600 Accuracy: 85.42857142857143%\n","Epoch 292/600 Accuracy: 88.26428571428572%\n","Epoch 293/600 Accuracy: 84.63571428571429%\n","Epoch 294/600 Accuracy: 87.55714285714285%\n","Epoch 295/600 Accuracy: 83.29285714285714%\n","Epoch 296/600 Accuracy: 86.93809523809523%\n","Epoch 297/600 Accuracy: 83.17857142857143%\n","Epoch 298/600 Accuracy: 85.71904761904761%\n","Epoch 299/600 Accuracy: 82.09285714285714%\n","Epoch 300/600 Accuracy: 79.18571428571428%\n","Epoch 301/600 Accuracy: 83.2952380952381%\n","Epoch 302/600 Accuracy: 82.38333333333333%\n","Epoch 303/600 Accuracy: 80.71190476190476%\n","Epoch 304/600 Accuracy: 74.33333333333333%\n","Epoch 305/600 Accuracy: 88.4952380952381%\n","Epoch 306/600 Accuracy: 89.67142857142856%\n","Epoch 307/600 Accuracy: 89.39047619047619%\n","Epoch 308/600 Accuracy: 90.18809523809523%\n","Epoch 309/600 Accuracy: 89.9095238095238%\n","Epoch 310/600 Accuracy: 90.47619047619048%\n","Epoch 311/600 Accuracy: 90.29761904761905%\n","Epoch 312/600 Accuracy: 90.68333333333334%\n","Epoch 313/600 Accuracy: 90.53095238095239%\n","Epoch 314/600 Accuracy: 90.81190476190476%\n","Epoch 315/600 Accuracy: 90.7%\n","Epoch 316/600 Accuracy: 90.88809523809523%\n","Epoch 317/600 Accuracy: 90.83095238095238%\n","Epoch 318/600 Accuracy: 90.92857142857143%\n","Epoch 319/600 Accuracy: 90.88809523809523%\n","Epoch 320/600 Accuracy: 90.95238095238095%\n","Epoch 321/600 Accuracy: 90.88333333333334%\n","Epoch 322/600 Accuracy: 90.95%\n","Epoch 323/600 Accuracy: 90.81190476190476%\n","Epoch 324/600 Accuracy: 90.94285714285715%\n","Epoch 325/600 Accuracy: 90.63095238095238%\n","Epoch 326/600 Accuracy: 90.6952380952381%\n","Epoch 327/600 Accuracy: 90.1547619047619%\n","Epoch 328/600 Accuracy: 90.07142857142857%\n","Epoch 329/600 Accuracy: 88.96904761904761%\n","Epoch 330/600 Accuracy: 88.12142857142857%\n","Epoch 331/600 Accuracy: 85.28571428571429%\n","Epoch 332/600 Accuracy: 79.81190476190476%\n","Epoch 333/600 Accuracy: 82.13095238095238%\n","Epoch 334/600 Accuracy: 83.72619047619048%\n","Epoch 335/600 Accuracy: 82.82380952380952%\n","Epoch 336/600 Accuracy: 76.71190476190476%\n","Epoch 337/600 Accuracy: 78.95476190476191%\n","Epoch 338/600 Accuracy: 76.63333333333333%\n","Epoch 339/600 Accuracy: 82.98809523809524%\n","Epoch 340/600 Accuracy: 75.60714285714286%\n","Epoch 341/600 Accuracy: 84.9047619047619%\n","Epoch 342/600 Accuracy: 85.59523809523809%\n","Epoch 343/600 Accuracy: 88.4452380952381%\n","Epoch 344/600 Accuracy: 86.32857142857144%\n","Epoch 345/600 Accuracy: 88.55%\n","Epoch 346/600 Accuracy: 85.03333333333333%\n","Epoch 347/600 Accuracy: 86.01904761904761%\n","Epoch 348/600 Accuracy: 74.95%\n","Epoch 349/600 Accuracy: 86.71428571428571%\n","Epoch 350/600 Accuracy: 82.85238095238095%\n","Epoch 351/600 Accuracy: 85.88333333333334%\n","Epoch 352/600 Accuracy: 80.97142857142858%\n","Epoch 353/600 Accuracy: 85.93333333333332%\n","Epoch 354/600 Accuracy: 83.2452380952381%\n","Epoch 355/600 Accuracy: 86.82142857142857%\n","Epoch 356/600 Accuracy: 85.37619047619047%\n","Epoch 357/600 Accuracy: 86.45238095238095%\n","Epoch 358/600 Accuracy: 84.82142857142857%\n","Epoch 359/600 Accuracy: 85.98809523809524%\n","Epoch 360/600 Accuracy: 84.26428571428572%\n","Epoch 361/600 Accuracy: 85.02380952380952%\n","Epoch 362/600 Accuracy: 83.12857142857143%\n","Epoch 363/600 Accuracy: 83.48095238095237%\n","Epoch 364/600 Accuracy: 84.11666666666666%\n","Epoch 365/600 Accuracy: 85.53809523809524%\n","Epoch 366/600 Accuracy: 86.97142857142856%\n","Epoch 367/600 Accuracy: 88.68333333333334%\n","Epoch 368/600 Accuracy: 89.1952380952381%\n","Epoch 369/600 Accuracy: 89.96190476190476%\n","Epoch 370/600 Accuracy: 89.10238095238095%\n","Epoch 371/600 Accuracy: 89.72142857142858%\n","Epoch 372/600 Accuracy: 87.93809523809524%\n","Epoch 373/600 Accuracy: 88.92380952380952%\n","Epoch 374/600 Accuracy: 85.4452380952381%\n","Epoch 375/600 Accuracy: 87.86190476190477%\n","Epoch 376/600 Accuracy: 83.10714285714286%\n","Epoch 377/600 Accuracy: 88.46428571428572%\n","Epoch 378/600 Accuracy: 85.70952380952382%\n","Epoch 379/600 Accuracy: 88.72619047619048%\n","Epoch 380/600 Accuracy: 86.57380952380952%\n","Epoch 381/600 Accuracy: 89.10714285714286%\n","Epoch 382/600 Accuracy: 87.76904761904763%\n","Epoch 383/600 Accuracy: 89.67619047619047%\n","Epoch 384/600 Accuracy: 88.91190476190476%\n","Epoch 385/600 Accuracy: 90.15952380952382%\n","Epoch 386/600 Accuracy: 89.65714285714286%\n","Epoch 387/600 Accuracy: 90.46904761904761%\n","Epoch 388/600 Accuracy: 90.20714285714286%\n","Epoch 389/600 Accuracy: 90.61190476190475%\n","Epoch 390/600 Accuracy: 90.35952380952381%\n","Epoch 391/600 Accuracy: 90.54761904761904%\n","Epoch 392/600 Accuracy: 90.29523809523809%\n","Epoch 393/600 Accuracy: 90.31666666666666%\n","Epoch 394/600 Accuracy: 90.02619047619046%\n","Epoch 395/600 Accuracy: 89.65238095238095%\n","Epoch 396/600 Accuracy: 89.33809523809524%\n","Epoch 397/600 Accuracy: 87.44761904761906%\n","Epoch 398/600 Accuracy: 85.52142857142857%\n","Epoch 399/600 Accuracy: 74.68333333333334%\n","Epoch 400/600 Accuracy: 83.2357142857143%\n","Epoch 401/600 Accuracy: 81.06904761904762%\n","Epoch 402/600 Accuracy: 80.81428571428572%\n","Epoch 403/600 Accuracy: 81.36666666666666%\n","Epoch 404/600 Accuracy: 79.99285714285715%\n","Epoch 405/600 Accuracy: 85.30714285714286%\n","Epoch 406/600 Accuracy: 85.04523809523809%\n","Epoch 407/600 Accuracy: 86.21428571428571%\n","Epoch 408/600 Accuracy: 83.66190476190476%\n","Epoch 409/600 Accuracy: 83.0904761904762%\n","Epoch 410/600 Accuracy: 70.37142857142857%\n","Epoch 411/600 Accuracy: 77.50714285714285%\n","Epoch 412/600 Accuracy: 68.50714285714285%\n","Epoch 413/600 Accuracy: 76.6547619047619%\n","Epoch 414/600 Accuracy: 80.34523809523809%\n","Epoch 415/600 Accuracy: 82.48571428571428%\n","Epoch 416/600 Accuracy: 81.38095238095238%\n","Epoch 417/600 Accuracy: 84.10238095238095%\n","Epoch 418/600 Accuracy: 80.47380952380952%\n","Epoch 419/600 Accuracy: 87.67142857142856%\n","Epoch 420/600 Accuracy: 89.59047619047618%\n","Epoch 421/600 Accuracy: 89.70714285714286%\n","Epoch 422/600 Accuracy: 90.46190476190476%\n","Epoch 423/600 Accuracy: 90.60952380952381%\n","Epoch 424/600 Accuracy: 90.86428571428571%\n","Epoch 425/600 Accuracy: 90.90238095238095%\n","Epoch 426/600 Accuracy: 90.98571428571428%\n","Epoch 427/600 Accuracy: 90.98333333333333%\n","Epoch 428/600 Accuracy: 91.02142857142857%\n","Epoch 429/600 Accuracy: 91.02380952380953%\n","Epoch 430/600 Accuracy: 91.03333333333333%\n","Epoch 431/600 Accuracy: 91.03809523809524%\n","Epoch 432/600 Accuracy: 91.02857142857142%\n","Epoch 433/600 Accuracy: 91.03095238095239%\n","Epoch 434/600 Accuracy: 91.02142857142857%\n","Epoch 435/600 Accuracy: 91.03333333333333%\n","Epoch 436/600 Accuracy: 90.97142857142858%\n","Epoch 437/600 Accuracy: 90.96666666666667%\n","Epoch 438/600 Accuracy: 90.86666666666666%\n","Epoch 439/600 Accuracy: 90.82380952380953%\n","Epoch 440/600 Accuracy: 90.58333333333334%\n","Epoch 441/600 Accuracy: 90.50238095238096%\n","Epoch 442/600 Accuracy: 90.10952380952381%\n","Epoch 443/600 Accuracy: 89.73571428571428%\n","Epoch 444/600 Accuracy: 89.01190476190476%\n","Epoch 445/600 Accuracy: 87.94047619047619%\n","Epoch 446/600 Accuracy: 85.90952380952382%\n","Epoch 447/600 Accuracy: 82.42619047619047%\n","Epoch 448/600 Accuracy: 80.7%\n","Epoch 449/600 Accuracy: 79.7452380952381%\n","Epoch 450/600 Accuracy: 86.96666666666667%\n","Epoch 451/600 Accuracy: 87.29761904761905%\n","Epoch 452/600 Accuracy: 87.35952380952381%\n","Epoch 453/600 Accuracy: 87.18333333333334%\n","Epoch 454/600 Accuracy: 87.63095238095238%\n","Epoch 455/600 Accuracy: 87.75238095238095%\n","Epoch 456/600 Accuracy: 88.25952380952381%\n","Epoch 457/600 Accuracy: 88.52142857142857%\n","Epoch 458/600 Accuracy: 89.11666666666666%\n","Epoch 459/600 Accuracy: 89.31190476190476%\n","Epoch 460/600 Accuracy: 90.01428571428572%\n","Epoch 461/600 Accuracy: 90.10714285714285%\n","Epoch 462/600 Accuracy: 90.57619047619048%\n","Epoch 463/600 Accuracy: 90.54285714285714%\n","Epoch 464/600 Accuracy: 90.87380952380953%\n","Epoch 465/600 Accuracy: 90.70476190476191%\n","Epoch 466/600 Accuracy: 90.67380952380952%\n","Epoch 467/600 Accuracy: 90.32857142857142%\n","Epoch 468/600 Accuracy: 89.44047619047619%\n","Epoch 469/600 Accuracy: 86.01666666666667%\n","Epoch 470/600 Accuracy: 83.83333333333334%\n","Epoch 471/600 Accuracy: 81.65476190476191%\n","Epoch 472/600 Accuracy: 87.03333333333333%\n","Epoch 473/600 Accuracy: 89.0142857142857%\n","Epoch 474/600 Accuracy: 87.43095238095238%\n","Epoch 475/600 Accuracy: 88.4452380952381%\n","Epoch 476/600 Accuracy: 86.4547619047619%\n","Epoch 477/600 Accuracy: 87.65714285714286%\n","Epoch 478/600 Accuracy: 85.83333333333333%\n","Epoch 479/600 Accuracy: 86.40952380952382%\n","Epoch 480/600 Accuracy: 84.58095238095238%\n","Epoch 481/600 Accuracy: 82.50238095238095%\n","Epoch 482/600 Accuracy: 83.74047619047619%\n","Epoch 483/600 Accuracy: 82.66428571428571%\n","Epoch 484/600 Accuracy: 78.40714285714286%\n","Epoch 485/600 Accuracy: 74.71666666666667%\n","Epoch 486/600 Accuracy: 82.65714285714286%\n","Epoch 487/600 Accuracy: 87.23571428571428%\n","Epoch 488/600 Accuracy: 82.65%\n","Epoch 489/600 Accuracy: 85.76666666666667%\n","Epoch 490/600 Accuracy: 76.35238095238095%\n","Epoch 491/600 Accuracy: 89.35238095238095%\n","Epoch 492/600 Accuracy: 89.70714285714286%\n","Epoch 493/600 Accuracy: 89.74047619047619%\n","Epoch 494/600 Accuracy: 89.63809523809523%\n","Epoch 495/600 Accuracy: 89.37142857142857%\n","Epoch 496/600 Accuracy: 88.99047619047619%\n","Epoch 497/600 Accuracy: 88.43095238095238%\n","Epoch 498/600 Accuracy: 86.9452380952381%\n","Epoch 499/600 Accuracy: 87.46428571428572%\n","Epoch 500/600 Accuracy: 85.50714285714285%\n","Epoch 501/600 Accuracy: 88.17619047619047%\n","Epoch 502/600 Accuracy: 87.97857142857143%\n","Epoch 503/600 Accuracy: 87.91904761904762%\n","Epoch 504/600 Accuracy: 87.41666666666667%\n","Epoch 505/600 Accuracy: 87.12857142857143%\n","Epoch 506/600 Accuracy: 87.06904761904762%\n","Epoch 507/600 Accuracy: 86.19047619047619%\n","Epoch 508/600 Accuracy: 87.17857142857143%\n","Epoch 509/600 Accuracy: 86.22380952380952%\n","Epoch 510/600 Accuracy: 87.87380952380953%\n","Epoch 511/600 Accuracy: 87.17619047619047%\n","Epoch 512/600 Accuracy: 88.72857142857143%\n","Epoch 513/600 Accuracy: 87.84285714285714%\n","Epoch 514/600 Accuracy: 89.09761904761905%\n","Epoch 515/600 Accuracy: 87.09285714285714%\n","Epoch 516/600 Accuracy: 88.77142857142857%\n","Epoch 517/600 Accuracy: 85.26666666666667%\n","Epoch 518/600 Accuracy: 89.5404761904762%\n","Epoch 519/600 Accuracy: 87.95238095238095%\n","Epoch 520/600 Accuracy: 89.77619047619048%\n","Epoch 521/600 Accuracy: 88.37857142857143%\n","Epoch 522/600 Accuracy: 90.02619047619046%\n","Epoch 523/600 Accuracy: 89.01190476190476%\n","Epoch 524/600 Accuracy: 90.33333333333333%\n","Epoch 525/600 Accuracy: 89.67619047619047%\n","Epoch 526/600 Accuracy: 90.61190476190475%\n","Epoch 527/600 Accuracy: 90.38333333333334%\n","Epoch 528/600 Accuracy: 90.82142857142857%\n","Epoch 529/600 Accuracy: 90.80714285714285%\n","Epoch 530/600 Accuracy: 91.05%\n","Epoch 531/600 Accuracy: 91.03333333333333%\n","Epoch 532/600 Accuracy: 91.12380952380953%\n","Epoch 533/600 Accuracy: 91.11428571428571%\n","Epoch 534/600 Accuracy: 91.13571428571429%\n","Epoch 535/600 Accuracy: 91.07142857142857%\n","Epoch 536/600 Accuracy: 91.1047619047619%\n","Epoch 537/600 Accuracy: 90.95714285714286%\n","Epoch 538/600 Accuracy: 90.91666666666667%\n","Epoch 539/600 Accuracy: 90.52380952380953%\n","Epoch 540/600 Accuracy: 90.37857142857143%\n","Epoch 541/600 Accuracy: 88.82619047619048%\n","Epoch 542/600 Accuracy: 86.97380952380952%\n","Epoch 543/600 Accuracy: 82.0547619047619%\n","Epoch 544/600 Accuracy: 90.28095238095239%\n","Epoch 545/600 Accuracy: 90.5547619047619%\n","Epoch 546/600 Accuracy: 90.67142857142856%\n","Epoch 547/600 Accuracy: 90.30238095238096%\n","Epoch 548/600 Accuracy: 89.5452380952381%\n","Epoch 549/600 Accuracy: 88.32857142857144%\n","Epoch 550/600 Accuracy: 82.13095238095238%\n","Epoch 551/600 Accuracy: 87.82380952380953%\n","Epoch 552/600 Accuracy: 89.17142857142856%\n","Epoch 553/600 Accuracy: 89.09523809523809%\n","Epoch 554/600 Accuracy: 88.31666666666666%\n","Epoch 555/600 Accuracy: 86.05000000000001%\n","Epoch 556/600 Accuracy: 85.48809523809524%\n","Epoch 557/600 Accuracy: 82.88333333333333%\n","Epoch 558/600 Accuracy: 89.41666666666667%\n","Epoch 559/600 Accuracy: 90.35714285714286%\n","Epoch 560/600 Accuracy: 90.58095238095238%\n","Epoch 561/600 Accuracy: 90.63809523809525%\n","Epoch 562/600 Accuracy: 90.79523809523809%\n","Epoch 563/600 Accuracy: 90.69285714285714%\n","Epoch 564/600 Accuracy: 90.88095238095238%\n","Epoch 565/600 Accuracy: 90.55952380952381%\n","Epoch 566/600 Accuracy: 90.77142857142857%\n","Epoch 567/600 Accuracy: 89.90714285714286%\n","Epoch 568/600 Accuracy: 90.01428571428572%\n","Epoch 569/600 Accuracy: 87.01904761904761%\n","Epoch 570/600 Accuracy: 87.72380952380952%\n","Epoch 571/600 Accuracy: 82.78571428571428%\n","Epoch 572/600 Accuracy: 90.07857142857144%\n","Epoch 573/600 Accuracy: 89.63333333333333%\n","Epoch 574/600 Accuracy: 89.73095238095237%\n","Epoch 575/600 Accuracy: 88.79523809523809%\n","Epoch 576/600 Accuracy: 87.83095238095238%\n","Epoch 577/600 Accuracy: 85.54523809523809%\n","Epoch 578/600 Accuracy: 81.98809523809524%\n","Epoch 579/600 Accuracy: 87.11190476190475%\n","Epoch 580/600 Accuracy: 87.59523809523809%\n","Epoch 581/600 Accuracy: 86.08095238095238%\n","Epoch 582/600 Accuracy: 82.56428571428572%\n","Epoch 583/600 Accuracy: 75.13095238095238%\n","Epoch 584/600 Accuracy: 78.03571428571429%\n","Epoch 585/600 Accuracy: 76.39761904761905%\n","Epoch 586/600 Accuracy: 69.5904761904762%\n","Epoch 587/600 Accuracy: 64.68809523809523%\n","Epoch 588/600 Accuracy: 71.57142857142857%\n","Epoch 589/600 Accuracy: 74.5904761904762%\n","Epoch 590/600 Accuracy: 84.26190476190476%\n","Epoch 591/600 Accuracy: 88.33809523809524%\n","Epoch 592/600 Accuracy: 84.42380952380952%\n","Epoch 593/600 Accuracy: 90.09761904761905%\n","Epoch 594/600 Accuracy: 88.78333333333333%\n","Epoch 595/600 Accuracy: 89.46904761904761%\n","Epoch 596/600 Accuracy: 86.52380952380952%\n","Epoch 597/600 Accuracy: 89.06428571428572%\n","Epoch 598/600 Accuracy: 86.56190476190476%\n","Epoch 599/600 Accuracy: 89.06428571428572%\n","Epoch 600/600 Accuracy: 87.28571428571429%\n","       ImageId  Label\n","0            1      2\n","1            2      0\n","2            3      9\n","3            4      7\n","4            5      3\n","...        ...    ...\n","27995    27996      9\n","27996    27997      7\n","27997    27998      3\n","27998    27999      9\n","27999    28000      2\n","\n","[28000 rows x 2 columns]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import scipy as sci\n","import matplotlib.pyplot as plt\n","#Importing libaries \n","\n","\n","path = \"/kaggle/input/digit-recognizer/train.csv\"\n","path1 = \"/kaggle/input/digit-recognizer/test.csv\"\n","data = pd.read_csv(path, engine='c')\n","test_data = pd.read_csv(path1, engine='c')\n","test_data = test_data/255.0\n","test_data = test_data.T\n","label_1 = data['label']\n","label_1 = label_1.T\n","\n","data = np.array(data)\n","m,n = data.shape\n","train_data = data[0:m].T\n","X_train = train_data[1:n]\n","X_train = X_train/255.0\n","#Preprocessing the data\n","\n","class Model(object):\n","\n","    def __init__(self, input_dim=784, output_dim=10):\n","        self.num_neurons = 2048\n","        \n","        self.w_1 = np.random.randn(self.num_neurons, input_dim) * np.sqrt(2./input_dim)\n","        self.w_2 = np.random.randn(self.num_neurons, self.num_neurons) * np.sqrt(2./10)\n","        self.w_3 = np.random.randn(output_dim, self.num_neurons) * np.sqrt(2./10)\n","        \n","        self.b_1 = np.zeros((self.num_neurons, 1))\n","        self.b_2 = np.zeros((self.num_neurons, 1))\n","        self.b_3 = np.zeros((output_dim,1))\n","        \n","        self.learning_rate = 1e-5\n","        self.epochs = 600\n","        \n","#Kaiming initialization, useful in normalisation of parameters and to prevent model being overfitting.\n","\n","    def sigmoid(self,x):\n","        return sci.special.expit(x)\n","    \n","    def sigmoid_derivative(self,x):\n","        return self.sigmoid(x)*(1-self.sigmoid(x))\n","    \n","    def ReLU(self, x):\n","        return np.maximum(0, x)\n","\n","    def ReLU_derivative(self, x):\n","        return np.where(x > 0, 1.0, 0.0)\n","\n","    def ELU(self, x):\n","        return np.where(x >= 0.0, x, self.alpha * (np.exp(x) - 1))\n","\n","    def ELU_deriv(self,x):\n","        return np.where(x >= 0, 1, self.alpha * np.exp(x))\n","\n","    def softmax(self, z):\n","        e_z = np.exp(z-np.max(z))\n","        return sci.special.softmax(e_z)\n","    \n","    def softmax_backward(self,z):\n","        do_dz = self.softmax(1-self.softmax)\n","        \n","    \n","#Defining a set of activation functions for the convenience of changing act. functions below\n","\n","\n","    def Forward(self, X_train):\n","        self.sum_1 = np.dot(self.w_1, X_train) + self.b_1\n","        self.output_1 = self.sigmoid(self.sum_1)\n","        #Second layer, using Sigmoid as activation\n","\n","        self.sum_2 = np.dot(self.w_2, self.output_1) + self.b_2\n","        self.output_2 = self.sigmoid(self.sum_2)\n","        #Third Layer, using Sigmoid as activation\n","        \n","        self.sum_3 = np.dot(self.w_3, self.output_2)+self.b_3\n","        self.output_3 = self.sigmoid(self.sum_3)\n","        #Fourth Layer, using Sigmoid as activation\n","        \n","        self.predictions = np.argmax(self.output_3, axis=0)\n","        return self.predictions\n","    \n","    #FeedForward Propagation, used to predict the label of the data.\n","    \n","    \n","    def Backward(self, label_1, X_train):\n","        \n","        one_hot_labels = np.eye(10)[label_1].T\n","        self.error = self.output_3 - one_hot_labels\n","        self.delta_3 = self.error*self.sigmoid_derivative(self.output_3)\n","        self.d_w_3 = np.dot(self.delta_3, self.output_2.T)  \n","        self.d_b_3 = np.sum(self.delta_3, axis=1, keepdims=True)\n","    \n","        self.delta_2 = np.dot(self.w_3.T, self.delta_3)*self.sigmoid_derivative(self.output_2)\n","        self.d_w_2 = np.dot(self.delta_2, self.output_1.T)\n","        self.d_b_2 = np.sum(self.delta_2, axis=1, keepdims=True)\n","    \n","        self.delta_1 = np.dot(self.w_2.T, self.delta_2) * self.sigmoid_derivative(self.output_1)\n","        self.d_w_1 = np.dot(self.delta_1, X_train.T)\n","        self.d_b_1 = np.sum(self.delta_1, axis=1, keepdims=True)\n","        \n","#Backwardpropagation, this program used gradient descent method to optimize the model\n","        \n","\n","    def update_params(self):\n","        self.w_1 -= self.learning_rate * self.d_w_1\n","        self.w_2 -= self.learning_rate * self.d_w_2\n","        self.w_3 -= self.learning_rate * self.d_w_3\n","        \n","        self.b_1 -= self.learning_rate * self.d_b_1\n","        self.b_2 -= self.learning_rate * self.d_b_2\n","        self.b_3 -= self.learning_rate * self.d_b_3\n","        \n","#Updating parameters\n","\n","    def compute_accuracy(self, label_1):\n","        correct_predictions = np.sum(self.predictions == label_1)\n","        total_predictions = self.predictions.shape[0]\n","        self.accuracy = correct_predictions / total_predictions\n","        \n","\n","    def fit(self, X_train, label_1):\n","        \n","        for epoch in range(self.epochs):\n","            list_1 = list()\n","            self.Forward(X_train)\n","            self.Backward(label_1, X_train)\n","            self.update_params()\n","            self.compute_accuracy(label_1)\n","            list_1.append(self.accuracy)\n","            print(f\"Epoch {epoch + 1}/{self.epochs} Accuracy: {self.accuracy * 100}%\")\n","            #Create loop for training the mode\n","        \n","    def test(self,test_data):\n","        self.Forward(test_data)\n","        predictions = self.predictions\n","\n","# Create a DataFrame directly with 'ImageId' and 'Label'\n","        submission = pd.DataFrame({\n","        'ImageId': range(1, len(predictions) + 1),\n","        'Label': predictions\n","        })\n","\n","# Save the DataFrame to a CSV file\n","        submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\n","        print(submission)\n","        \n","\n","# Create an instance of the Model class\n","model = Model()\n","\n","# Train the model\n","model.fit(X_train, label_1)\n","model.test(test_data)"]},{"cell_type":"code","execution_count":null,"id":"34867f7c","metadata":{"papermill":{"duration":0.057614,"end_time":"2024-02-07T12:57:52.99399","exception":false,"start_time":"2024-02-07T12:57:52.936376","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4830a029","metadata":{"papermill":{"duration":0.057209,"end_time":"2024-02-07T12:57:53.109078","exception":false,"start_time":"2024-02-07T12:57:53.051869","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"},{"datasetId":19,"sourceId":420,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":17730.292148,"end_time":"2024-02-07T12:57:53.830697","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-07T08:02:23.538549","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}