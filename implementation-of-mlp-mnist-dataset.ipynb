{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619e6083",
   "metadata": {
    "papermill": {
     "duration": 0.002757,
     "end_time": "2024-02-05T16:30:27.104098",
     "exception": false,
     "start_time": "2024-02-05T16:30:27.101341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a simple 2 layer MLP of the MNIST dataset classification, where sigmoid are used as activation functions of all layers.\n",
    "\n",
    "All 42000 images belong to 10 classes.\n",
    "\n",
    "# 1. Preprocessing Stage\n",
    "\n",
    "- Before we put those images into the NN, we have to do some preprocessings to reduce overfitting and boost the accuracy.\n",
    "\n",
    "- X_train = X_train/255.0 is used to normalize the train_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. FeedForward Propagation\n",
    "\n",
    "Output of the neuron follows :\n",
    "\n",
    "$\\sum = wx + b$\n",
    "\n",
    "$o = sigmoid(\\sum)$\n",
    "\n",
    "Suppose $w_1,b_1$ be the weights and biases of the 1st layer, and $w_2, b_2$ be the weights and biases of the 2nd layer, thus, the output of each neuron in the output layer would be :\n",
    "\n",
    "$o_2 = sigmoid(w_2\\sum + b_2)$\n",
    "\n",
    "# 3. BackwardPropagation\n",
    "\n",
    "This algorithm uses gradient descent method as optimization method.\n",
    "\n",
    "Suppose $\\delta_1$ and $\\delta_2$ be the **error** of 1st and 2nd layer respectively, $\\vec t_m = (t_1,t_2,....,t_m)$ and $\\vec y_m = (y_1, y_2,....,y_m)$ be the target and output vector respectively, we have in the second layer :\n",
    "\n",
    "$\\delta = \\frac{\\partial E}{\\partial w_ij} = y_i(y_i - t_i)(1-y_i)$\n",
    "\n",
    "\n",
    "# 4. Activation Functions\n",
    "\n",
    "1. ReLu\n",
    "- Relu is the most popular activation function in machine learning, it is defined as :\n",
    "\n",
    "$ReLu(x) = x$ for x>0\n",
    "\n",
    "$ReLu(x) = 0$ for x<0\n",
    "\n",
    "Relu is famous of it's simplifcity of it's derivative function, the derivative of ReLu is :\n",
    "\n",
    "$ReLU'(x) = 0$ for x<0\n",
    "\n",
    "$ReLU'(x) = 1$ for x>0\n",
    "\n",
    "2. Softmax\n",
    "- Softmax is another popular activation function, it can helps transform the output into probability, the softmax function is defined as :\n",
    "\n",
    "$softmax(z)_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}$\n",
    "\n",
    "3. Sigmoid\n",
    "\n",
    "- Sigmoid is a type of activation function which has a S shape, in this program, the sigmoid function we used is :\n",
    "\n",
    "$Sigmoid(x) = \\frac{1}{1+e^{-x}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac484fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T16:30:27.110959Z",
     "iopub.status.busy": "2024-02-05T16:30:27.110428Z",
     "iopub.status.idle": "2024-02-05T16:43:21.309913Z",
     "shell.execute_reply": "2024-02-05T16:43:21.308063Z"
    },
    "papermill": {
     "duration": 774.206264,
     "end_time": "2024-02-05T16:43:21.312648",
     "exception": false,
     "start_time": "2024-02-05T16:30:27.106384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 Accuracy: 11.154761904761905%\n",
      "Epoch 2/500 Accuracy: 10.485714285714286%\n",
      "Epoch 3/500 Accuracy: 17.223809523809525%\n",
      "Epoch 4/500 Accuracy: 27.73809523809524%\n",
      "Epoch 5/500 Accuracy: 31.376190476190473%\n",
      "Epoch 6/500 Accuracy: 39.94761904761905%\n",
      "Epoch 7/500 Accuracy: 44.63809523809524%\n",
      "Epoch 8/500 Accuracy: 50.2547619047619%\n",
      "Epoch 9/500 Accuracy: 54.06428571428571%\n",
      "Epoch 10/500 Accuracy: 57.285714285714285%\n",
      "Epoch 11/500 Accuracy: 59.78809523809524%\n",
      "Epoch 12/500 Accuracy: 62.22380952380953%\n",
      "Epoch 13/500 Accuracy: 64.30238095238096%\n",
      "Epoch 14/500 Accuracy: 66.19761904761904%\n",
      "Epoch 15/500 Accuracy: 67.74761904761904%\n",
      "Epoch 16/500 Accuracy: 69.18571428571428%\n",
      "Epoch 17/500 Accuracy: 70.3952380952381%\n",
      "Epoch 18/500 Accuracy: 71.63571428571429%\n",
      "Epoch 19/500 Accuracy: 72.77380952380952%\n",
      "Epoch 20/500 Accuracy: 73.74047619047619%\n",
      "Epoch 21/500 Accuracy: 74.66904761904762%\n",
      "Epoch 22/500 Accuracy: 75.38571428571429%\n",
      "Epoch 23/500 Accuracy: 76.02142857142857%\n",
      "Epoch 24/500 Accuracy: 76.61666666666666%\n",
      "Epoch 25/500 Accuracy: 77.19285714285714%\n",
      "Epoch 26/500 Accuracy: 77.70714285714286%\n",
      "Epoch 27/500 Accuracy: 78.15952380952382%\n",
      "Epoch 28/500 Accuracy: 78.64761904761905%\n",
      "Epoch 29/500 Accuracy: 79.01428571428572%\n",
      "Epoch 30/500 Accuracy: 79.38095238095238%\n",
      "Epoch 31/500 Accuracy: 79.69285714285715%\n",
      "Epoch 32/500 Accuracy: 80.03571428571429%\n",
      "Epoch 33/500 Accuracy: 80.28571428571428%\n",
      "Epoch 34/500 Accuracy: 80.5547619047619%\n",
      "Epoch 35/500 Accuracy: 80.77142857142857%\n",
      "Epoch 36/500 Accuracy: 81.00238095238095%\n",
      "Epoch 37/500 Accuracy: 81.2642857142857%\n",
      "Epoch 38/500 Accuracy: 81.43571428571428%\n",
      "Epoch 39/500 Accuracy: 81.62857142857143%\n",
      "Epoch 40/500 Accuracy: 81.75714285714287%\n",
      "Epoch 41/500 Accuracy: 81.92142857142856%\n",
      "Epoch 42/500 Accuracy: 82.04285714285714%\n",
      "Epoch 43/500 Accuracy: 82.19999999999999%\n",
      "Epoch 44/500 Accuracy: 82.34523809523809%\n",
      "Epoch 45/500 Accuracy: 82.45238095238095%\n",
      "Epoch 46/500 Accuracy: 82.62619047619047%\n",
      "Epoch 47/500 Accuracy: 82.74047619047619%\n",
      "Epoch 48/500 Accuracy: 82.86666666666666%\n",
      "Epoch 49/500 Accuracy: 82.93333333333334%\n",
      "Epoch 50/500 Accuracy: 83.0547619047619%\n",
      "Epoch 51/500 Accuracy: 83.16666666666667%\n",
      "Epoch 52/500 Accuracy: 83.26666666666667%\n",
      "Epoch 53/500 Accuracy: 83.38095238095238%\n",
      "Epoch 54/500 Accuracy: 83.50952380952381%\n",
      "Epoch 55/500 Accuracy: 83.63333333333334%\n",
      "Epoch 56/500 Accuracy: 83.71904761904761%\n",
      "Epoch 57/500 Accuracy: 83.80714285714286%\n",
      "Epoch 58/500 Accuracy: 83.89999999999999%\n",
      "Epoch 59/500 Accuracy: 83.96666666666667%\n",
      "Epoch 60/500 Accuracy: 84.03333333333333%\n",
      "Epoch 61/500 Accuracy: 84.08571428571429%\n",
      "Epoch 62/500 Accuracy: 84.1595238095238%\n",
      "Epoch 63/500 Accuracy: 84.24285714285715%\n",
      "Epoch 64/500 Accuracy: 84.33571428571427%\n",
      "Epoch 65/500 Accuracy: 84.40238095238095%\n",
      "Epoch 66/500 Accuracy: 84.47380952380954%\n",
      "Epoch 67/500 Accuracy: 84.54047619047618%\n",
      "Epoch 68/500 Accuracy: 84.57857142857142%\n",
      "Epoch 69/500 Accuracy: 84.63571428571429%\n",
      "Epoch 70/500 Accuracy: 84.69761904761904%\n",
      "Epoch 71/500 Accuracy: 84.74761904761905%\n",
      "Epoch 72/500 Accuracy: 84.79761904761904%\n",
      "Epoch 73/500 Accuracy: 84.83571428571427%\n",
      "Epoch 74/500 Accuracy: 84.87142857142858%\n",
      "Epoch 75/500 Accuracy: 84.92380952380952%\n",
      "Epoch 76/500 Accuracy: 84.96190476190476%\n",
      "Epoch 77/500 Accuracy: 85.02380952380952%\n",
      "Epoch 78/500 Accuracy: 85.05%\n",
      "Epoch 79/500 Accuracy: 85.1%\n",
      "Epoch 80/500 Accuracy: 85.12380952380953%\n",
      "Epoch 81/500 Accuracy: 85.16666666666667%\n",
      "Epoch 82/500 Accuracy: 85.20952380952382%\n",
      "Epoch 83/500 Accuracy: 85.2547619047619%\n",
      "Epoch 84/500 Accuracy: 85.3047619047619%\n",
      "Epoch 85/500 Accuracy: 85.33571428571427%\n",
      "Epoch 86/500 Accuracy: 85.37619047619047%\n",
      "Epoch 87/500 Accuracy: 85.41428571428571%\n",
      "Epoch 88/500 Accuracy: 85.45%\n",
      "Epoch 89/500 Accuracy: 85.47857142857143%\n",
      "Epoch 90/500 Accuracy: 85.5047619047619%\n",
      "Epoch 91/500 Accuracy: 85.5547619047619%\n",
      "Epoch 92/500 Accuracy: 85.56666666666666%\n",
      "Epoch 93/500 Accuracy: 85.59285714285714%\n",
      "Epoch 94/500 Accuracy: 85.63809523809523%\n",
      "Epoch 95/500 Accuracy: 85.66904761904762%\n",
      "Epoch 96/500 Accuracy: 85.71190476190476%\n",
      "Epoch 97/500 Accuracy: 85.74761904761905%\n",
      "Epoch 98/500 Accuracy: 85.8%\n",
      "Epoch 99/500 Accuracy: 85.83571428571429%\n",
      "Epoch 100/500 Accuracy: 85.89047619047619%\n",
      "Epoch 101/500 Accuracy: 85.94047619047619%\n",
      "Epoch 102/500 Accuracy: 85.97142857142858%\n",
      "Epoch 103/500 Accuracy: 86.00238095238095%\n",
      "Epoch 104/500 Accuracy: 86.0142857142857%\n",
      "Epoch 105/500 Accuracy: 86.04761904761905%\n",
      "Epoch 106/500 Accuracy: 86.06666666666666%\n",
      "Epoch 107/500 Accuracy: 86.1047619047619%\n",
      "Epoch 108/500 Accuracy: 86.13809523809523%\n",
      "Epoch 109/500 Accuracy: 86.16190476190476%\n",
      "Epoch 110/500 Accuracy: 86.18809523809524%\n",
      "Epoch 111/500 Accuracy: 86.22380952380952%\n",
      "Epoch 112/500 Accuracy: 86.25%\n",
      "Epoch 113/500 Accuracy: 86.28095238095239%\n",
      "Epoch 114/500 Accuracy: 86.30714285714286%\n",
      "Epoch 115/500 Accuracy: 86.32380952380953%\n",
      "Epoch 116/500 Accuracy: 86.34285714285714%\n",
      "Epoch 117/500 Accuracy: 86.36666666666667%\n",
      "Epoch 118/500 Accuracy: 86.40476190476191%\n",
      "Epoch 119/500 Accuracy: 86.41190476190475%\n",
      "Epoch 120/500 Accuracy: 86.43333333333332%\n",
      "Epoch 121/500 Accuracy: 86.46190476190476%\n",
      "Epoch 122/500 Accuracy: 86.47619047619047%\n",
      "Epoch 123/500 Accuracy: 86.5047619047619%\n",
      "Epoch 124/500 Accuracy: 86.54523809523809%\n",
      "Epoch 125/500 Accuracy: 86.56666666666666%\n",
      "Epoch 126/500 Accuracy: 86.59285714285714%\n",
      "Epoch 127/500 Accuracy: 86.61190476190475%\n",
      "Epoch 128/500 Accuracy: 86.61666666666666%\n",
      "Epoch 129/500 Accuracy: 86.62857142857143%\n",
      "Epoch 130/500 Accuracy: 86.66190476190476%\n",
      "Epoch 131/500 Accuracy: 86.66428571428571%\n",
      "Epoch 132/500 Accuracy: 86.68809523809524%\n",
      "Epoch 133/500 Accuracy: 86.7%\n",
      "Epoch 134/500 Accuracy: 86.72619047619048%\n",
      "Epoch 135/500 Accuracy: 86.73809523809524%\n",
      "Epoch 136/500 Accuracy: 86.77619047619048%\n",
      "Epoch 137/500 Accuracy: 86.80238095238096%\n",
      "Epoch 138/500 Accuracy: 86.83571428571429%\n",
      "Epoch 139/500 Accuracy: 86.85000000000001%\n",
      "Epoch 140/500 Accuracy: 86.85952380952381%\n",
      "Epoch 141/500 Accuracy: 86.88571428571429%\n",
      "Epoch 142/500 Accuracy: 86.90714285714286%\n",
      "Epoch 143/500 Accuracy: 86.93333333333332%\n",
      "Epoch 144/500 Accuracy: 86.9547619047619%\n",
      "Epoch 145/500 Accuracy: 86.96904761904763%\n",
      "Epoch 146/500 Accuracy: 86.9857142857143%\n",
      "Epoch 147/500 Accuracy: 87.01190476190476%\n",
      "Epoch 148/500 Accuracy: 87.02619047619048%\n",
      "Epoch 149/500 Accuracy: 87.05000000000001%\n",
      "Epoch 150/500 Accuracy: 87.06904761904762%\n",
      "Epoch 151/500 Accuracy: 87.07857142857142%\n",
      "Epoch 152/500 Accuracy: 87.1047619047619%\n",
      "Epoch 153/500 Accuracy: 87.12619047619047%\n",
      "Epoch 154/500 Accuracy: 87.14761904761905%\n",
      "Epoch 155/500 Accuracy: 87.17619047619047%\n",
      "Epoch 156/500 Accuracy: 87.18333333333334%\n",
      "Epoch 157/500 Accuracy: 87.18571428571428%\n",
      "Epoch 158/500 Accuracy: 87.19285714285714%\n",
      "Epoch 159/500 Accuracy: 87.21190476190476%\n",
      "Epoch 160/500 Accuracy: 87.21666666666667%\n",
      "Epoch 161/500 Accuracy: 87.23333333333333%\n",
      "Epoch 162/500 Accuracy: 87.2452380952381%\n",
      "Epoch 163/500 Accuracy: 87.2547619047619%\n",
      "Epoch 164/500 Accuracy: 87.25714285714285%\n",
      "Epoch 165/500 Accuracy: 87.26904761904763%\n",
      "Epoch 166/500 Accuracy: 87.27619047619048%\n",
      "Epoch 167/500 Accuracy: 87.29523809523809%\n",
      "Epoch 168/500 Accuracy: 87.30714285714286%\n",
      "Epoch 169/500 Accuracy: 87.33333333333333%\n",
      "Epoch 170/500 Accuracy: 87.35952380952381%\n",
      "Epoch 171/500 Accuracy: 87.37142857142857%\n",
      "Epoch 172/500 Accuracy: 87.38809523809525%\n",
      "Epoch 173/500 Accuracy: 87.39761904761905%\n",
      "Epoch 174/500 Accuracy: 87.40952380952382%\n",
      "Epoch 175/500 Accuracy: 87.43095238095238%\n",
      "Epoch 176/500 Accuracy: 87.42857142857143%\n",
      "Epoch 177/500 Accuracy: 87.44761904761906%\n",
      "Epoch 178/500 Accuracy: 87.4547619047619%\n",
      "Epoch 179/500 Accuracy: 87.46190476190476%\n",
      "Epoch 180/500 Accuracy: 87.48333333333333%\n",
      "Epoch 181/500 Accuracy: 87.49761904761904%\n",
      "Epoch 182/500 Accuracy: 87.52857142857144%\n",
      "Epoch 183/500 Accuracy: 87.5452380952381%\n",
      "Epoch 184/500 Accuracy: 87.5547619047619%\n",
      "Epoch 185/500 Accuracy: 87.57380952380952%\n",
      "Epoch 186/500 Accuracy: 87.59285714285714%\n",
      "Epoch 187/500 Accuracy: 87.60238095238095%\n",
      "Epoch 188/500 Accuracy: 87.61904761904762%\n",
      "Epoch 189/500 Accuracy: 87.63333333333333%\n",
      "Epoch 190/500 Accuracy: 87.65714285714286%\n",
      "Epoch 191/500 Accuracy: 87.66428571428571%\n",
      "Epoch 192/500 Accuracy: 87.68095238095238%\n",
      "Epoch 193/500 Accuracy: 87.68809523809524%\n",
      "Epoch 194/500 Accuracy: 87.70714285714286%\n",
      "Epoch 195/500 Accuracy: 87.71666666666667%\n",
      "Epoch 196/500 Accuracy: 87.72142857142858%\n",
      "Epoch 197/500 Accuracy: 87.74285714285715%\n",
      "Epoch 198/500 Accuracy: 87.75%\n",
      "Epoch 199/500 Accuracy: 87.75714285714285%\n",
      "Epoch 200/500 Accuracy: 87.76904761904763%\n",
      "Epoch 201/500 Accuracy: 87.78333333333333%\n",
      "Epoch 202/500 Accuracy: 87.79761904761905%\n",
      "Epoch 203/500 Accuracy: 87.81190476190476%\n",
      "Epoch 204/500 Accuracy: 87.83333333333333%\n",
      "Epoch 205/500 Accuracy: 87.8452380952381%\n",
      "Epoch 206/500 Accuracy: 87.8547619047619%\n",
      "Epoch 207/500 Accuracy: 87.85952380952381%\n",
      "Epoch 208/500 Accuracy: 87.86428571428571%\n",
      "Epoch 209/500 Accuracy: 87.87857142857143%\n",
      "Epoch 210/500 Accuracy: 87.88571428571429%\n",
      "Epoch 211/500 Accuracy: 87.90476190476191%\n",
      "Epoch 212/500 Accuracy: 87.91666666666667%\n",
      "Epoch 213/500 Accuracy: 87.92142857142858%\n",
      "Epoch 214/500 Accuracy: 87.93095238095238%\n",
      "Epoch 215/500 Accuracy: 87.93571428571428%\n",
      "Epoch 216/500 Accuracy: 87.95238095238095%\n",
      "Epoch 217/500 Accuracy: 87.96666666666667%\n",
      "Epoch 218/500 Accuracy: 87.97857142857143%\n",
      "Epoch 219/500 Accuracy: 87.99047619047619%\n",
      "Epoch 220/500 Accuracy: 87.99047619047619%\n",
      "Epoch 221/500 Accuracy: 87.99761904761905%\n",
      "Epoch 222/500 Accuracy: 88.0095238095238%\n",
      "Epoch 223/500 Accuracy: 88.0142857142857%\n",
      "Epoch 224/500 Accuracy: 88.02380952380953%\n",
      "Epoch 225/500 Accuracy: 88.0404761904762%\n",
      "Epoch 226/500 Accuracy: 88.06190476190477%\n",
      "Epoch 227/500 Accuracy: 88.06904761904762%\n",
      "Epoch 228/500 Accuracy: 88.07142857142857%\n",
      "Epoch 229/500 Accuracy: 88.08333333333334%\n",
      "Epoch 230/500 Accuracy: 88.08809523809525%\n",
      "Epoch 231/500 Accuracy: 88.10238095238095%\n",
      "Epoch 232/500 Accuracy: 88.10952380952381%\n",
      "Epoch 233/500 Accuracy: 88.11666666666666%\n",
      "Epoch 234/500 Accuracy: 88.12857142857143%\n",
      "Epoch 235/500 Accuracy: 88.13571428571429%\n",
      "Epoch 236/500 Accuracy: 88.1452380952381%\n",
      "Epoch 237/500 Accuracy: 88.1547619047619%\n",
      "Epoch 238/500 Accuracy: 88.16190476190476%\n",
      "Epoch 239/500 Accuracy: 88.17142857142856%\n",
      "Epoch 240/500 Accuracy: 88.18809523809524%\n",
      "Epoch 241/500 Accuracy: 88.1952380952381%\n",
      "Epoch 242/500 Accuracy: 88.2%\n",
      "Epoch 243/500 Accuracy: 88.2%\n",
      "Epoch 244/500 Accuracy: 88.2095238095238%\n",
      "Epoch 245/500 Accuracy: 88.21904761904761%\n",
      "Epoch 246/500 Accuracy: 88.23095238095237%\n",
      "Epoch 247/500 Accuracy: 88.23809523809524%\n",
      "Epoch 248/500 Accuracy: 88.25238095238095%\n",
      "Epoch 249/500 Accuracy: 88.25714285714285%\n",
      "Epoch 250/500 Accuracy: 88.26190476190476%\n",
      "Epoch 251/500 Accuracy: 88.27380952380952%\n",
      "Epoch 252/500 Accuracy: 88.29047619047618%\n",
      "Epoch 253/500 Accuracy: 88.30238095238096%\n",
      "Epoch 254/500 Accuracy: 88.3047619047619%\n",
      "Epoch 255/500 Accuracy: 88.31428571428572%\n",
      "Epoch 256/500 Accuracy: 88.31666666666666%\n",
      "Epoch 257/500 Accuracy: 88.33333333333333%\n",
      "Epoch 258/500 Accuracy: 88.3404761904762%\n",
      "Epoch 259/500 Accuracy: 88.35238095238095%\n",
      "Epoch 260/500 Accuracy: 88.35952380952381%\n",
      "Epoch 261/500 Accuracy: 88.36428571428571%\n",
      "Epoch 262/500 Accuracy: 88.36904761904762%\n",
      "Epoch 263/500 Accuracy: 88.38571428571429%\n",
      "Epoch 264/500 Accuracy: 88.40238095238095%\n",
      "Epoch 265/500 Accuracy: 88.40238095238095%\n",
      "Epoch 266/500 Accuracy: 88.40714285714286%\n",
      "Epoch 267/500 Accuracy: 88.41428571428571%\n",
      "Epoch 268/500 Accuracy: 88.41666666666667%\n",
      "Epoch 269/500 Accuracy: 88.42857142857142%\n",
      "Epoch 270/500 Accuracy: 88.4452380952381%\n",
      "Epoch 271/500 Accuracy: 88.44761904761906%\n",
      "Epoch 272/500 Accuracy: 88.45238095238095%\n",
      "Epoch 273/500 Accuracy: 88.46666666666667%\n",
      "Epoch 274/500 Accuracy: 88.47857142857143%\n",
      "Epoch 275/500 Accuracy: 88.49285714285713%\n",
      "Epoch 276/500 Accuracy: 88.5%\n",
      "Epoch 277/500 Accuracy: 88.50238095238096%\n",
      "Epoch 278/500 Accuracy: 88.50238095238096%\n",
      "Epoch 279/500 Accuracy: 88.51190476190476%\n",
      "Epoch 280/500 Accuracy: 88.52142857142857%\n",
      "Epoch 281/500 Accuracy: 88.52857142857142%\n",
      "Epoch 282/500 Accuracy: 88.53095238095237%\n",
      "Epoch 283/500 Accuracy: 88.5404761904762%\n",
      "Epoch 284/500 Accuracy: 88.5452380952381%\n",
      "Epoch 285/500 Accuracy: 88.5547619047619%\n",
      "Epoch 286/500 Accuracy: 88.55952380952381%\n",
      "Epoch 287/500 Accuracy: 88.57380952380952%\n",
      "Epoch 288/500 Accuracy: 88.57857142857142%\n",
      "Epoch 289/500 Accuracy: 88.58095238095238%\n",
      "Epoch 290/500 Accuracy: 88.59523809523809%\n",
      "Epoch 291/500 Accuracy: 88.60476190476192%\n",
      "Epoch 292/500 Accuracy: 88.60714285714286%\n",
      "Epoch 293/500 Accuracy: 88.61428571428571%\n",
      "Epoch 294/500 Accuracy: 88.61666666666666%\n",
      "Epoch 295/500 Accuracy: 88.63095238095238%\n",
      "Epoch 296/500 Accuracy: 88.64285714285714%\n",
      "Epoch 297/500 Accuracy: 88.64761904761906%\n",
      "Epoch 298/500 Accuracy: 88.65714285714286%\n",
      "Epoch 299/500 Accuracy: 88.6595238095238%\n",
      "Epoch 300/500 Accuracy: 88.67142857142856%\n",
      "Epoch 301/500 Accuracy: 88.67619047619047%\n",
      "Epoch 302/500 Accuracy: 88.68809523809524%\n",
      "Epoch 303/500 Accuracy: 88.69285714285714%\n",
      "Epoch 304/500 Accuracy: 88.7%\n",
      "Epoch 305/500 Accuracy: 88.70238095238095%\n",
      "Epoch 306/500 Accuracy: 88.71190476190476%\n",
      "Epoch 307/500 Accuracy: 88.71428571428571%\n",
      "Epoch 308/500 Accuracy: 88.71428571428571%\n",
      "Epoch 309/500 Accuracy: 88.71666666666667%\n",
      "Epoch 310/500 Accuracy: 88.72142857142858%\n",
      "Epoch 311/500 Accuracy: 88.71904761904761%\n",
      "Epoch 312/500 Accuracy: 88.72142857142858%\n",
      "Epoch 313/500 Accuracy: 88.72380952380952%\n",
      "Epoch 314/500 Accuracy: 88.73571428571428%\n",
      "Epoch 315/500 Accuracy: 88.74285714285715%\n",
      "Epoch 316/500 Accuracy: 88.74285714285715%\n",
      "Epoch 317/500 Accuracy: 88.75238095238095%\n",
      "Epoch 318/500 Accuracy: 88.7547619047619%\n",
      "Epoch 319/500 Accuracy: 88.76190476190476%\n",
      "Epoch 320/500 Accuracy: 88.77142857142857%\n",
      "Epoch 321/500 Accuracy: 88.77142857142857%\n",
      "Epoch 322/500 Accuracy: 88.78095238095239%\n",
      "Epoch 323/500 Accuracy: 88.78571428571429%\n",
      "Epoch 324/500 Accuracy: 88.78809523809524%\n",
      "Epoch 325/500 Accuracy: 88.79285714285714%\n",
      "Epoch 326/500 Accuracy: 88.79761904761905%\n",
      "Epoch 327/500 Accuracy: 88.80238095238096%\n",
      "Epoch 328/500 Accuracy: 88.81190476190476%\n",
      "Epoch 329/500 Accuracy: 88.80714285714286%\n",
      "Epoch 330/500 Accuracy: 88.8047619047619%\n",
      "Epoch 331/500 Accuracy: 88.8047619047619%\n",
      "Epoch 332/500 Accuracy: 88.82380952380953%\n",
      "Epoch 333/500 Accuracy: 88.81666666666666%\n",
      "Epoch 334/500 Accuracy: 88.81904761904762%\n",
      "Epoch 335/500 Accuracy: 88.82380952380953%\n",
      "Epoch 336/500 Accuracy: 88.83333333333333%\n",
      "Epoch 337/500 Accuracy: 88.83571428571429%\n",
      "Epoch 338/500 Accuracy: 88.83571428571429%\n",
      "Epoch 339/500 Accuracy: 88.83809523809524%\n",
      "Epoch 340/500 Accuracy: 88.8452380952381%\n",
      "Epoch 341/500 Accuracy: 88.85238095238095%\n",
      "Epoch 342/500 Accuracy: 88.8547619047619%\n",
      "Epoch 343/500 Accuracy: 88.86428571428571%\n",
      "Epoch 344/500 Accuracy: 88.87380952380953%\n",
      "Epoch 345/500 Accuracy: 88.87380952380953%\n",
      "Epoch 346/500 Accuracy: 88.88571428571429%\n",
      "Epoch 347/500 Accuracy: 88.88571428571429%\n",
      "Epoch 348/500 Accuracy: 88.88809523809523%\n",
      "Epoch 349/500 Accuracy: 88.8952380952381%\n",
      "Epoch 350/500 Accuracy: 88.8952380952381%\n",
      "Epoch 351/500 Accuracy: 88.8952380952381%\n",
      "Epoch 352/500 Accuracy: 88.90238095238095%\n",
      "Epoch 353/500 Accuracy: 88.9095238095238%\n",
      "Epoch 354/500 Accuracy: 88.91428571428571%\n",
      "Epoch 355/500 Accuracy: 88.91666666666667%\n",
      "Epoch 356/500 Accuracy: 88.92142857142858%\n",
      "Epoch 357/500 Accuracy: 88.92857142857142%\n",
      "Epoch 358/500 Accuracy: 88.93571428571428%\n",
      "Epoch 359/500 Accuracy: 88.94047619047619%\n",
      "Epoch 360/500 Accuracy: 88.94761904761906%\n",
      "Epoch 361/500 Accuracy: 88.95476190476191%\n",
      "Epoch 362/500 Accuracy: 88.96428571428572%\n",
      "Epoch 363/500 Accuracy: 88.97142857142856%\n",
      "Epoch 364/500 Accuracy: 88.97380952380952%\n",
      "Epoch 365/500 Accuracy: 88.98333333333333%\n",
      "Epoch 366/500 Accuracy: 88.9952380952381%\n",
      "Epoch 367/500 Accuracy: 89.00238095238096%\n",
      "Epoch 368/500 Accuracy: 89.0142857142857%\n",
      "Epoch 369/500 Accuracy: 89.01666666666667%\n",
      "Epoch 370/500 Accuracy: 89.01666666666667%\n",
      "Epoch 371/500 Accuracy: 89.02142857142857%\n",
      "Epoch 372/500 Accuracy: 89.02142857142857%\n",
      "Epoch 373/500 Accuracy: 89.03095238095237%\n",
      "Epoch 374/500 Accuracy: 89.03333333333333%\n",
      "Epoch 375/500 Accuracy: 89.03571428571428%\n",
      "Epoch 376/500 Accuracy: 89.0404761904762%\n",
      "Epoch 377/500 Accuracy: 89.0452380952381%\n",
      "Epoch 378/500 Accuracy: 89.0547619047619%\n",
      "Epoch 379/500 Accuracy: 89.05714285714285%\n",
      "Epoch 380/500 Accuracy: 89.05714285714285%\n",
      "Epoch 381/500 Accuracy: 89.06190476190477%\n",
      "Epoch 382/500 Accuracy: 89.06904761904761%\n",
      "Epoch 383/500 Accuracy: 89.06904761904761%\n",
      "Epoch 384/500 Accuracy: 89.07857142857142%\n",
      "Epoch 385/500 Accuracy: 89.08333333333334%\n",
      "Epoch 386/500 Accuracy: 89.08333333333334%\n",
      "Epoch 387/500 Accuracy: 89.08333333333334%\n",
      "Epoch 388/500 Accuracy: 89.09285714285714%\n",
      "Epoch 389/500 Accuracy: 89.09523809523809%\n",
      "Epoch 390/500 Accuracy: 89.10238095238095%\n",
      "Epoch 391/500 Accuracy: 89.10476190476192%\n",
      "Epoch 392/500 Accuracy: 89.10952380952381%\n",
      "Epoch 393/500 Accuracy: 89.11666666666666%\n",
      "Epoch 394/500 Accuracy: 89.12142857142857%\n",
      "Epoch 395/500 Accuracy: 89.12142857142857%\n",
      "Epoch 396/500 Accuracy: 89.12857142857142%\n",
      "Epoch 397/500 Accuracy: 89.13333333333333%\n",
      "Epoch 398/500 Accuracy: 89.14047619047619%\n",
      "Epoch 399/500 Accuracy: 89.14285714285714%\n",
      "Epoch 400/500 Accuracy: 89.14761904761905%\n",
      "Epoch 401/500 Accuracy: 89.14761904761905%\n",
      "Epoch 402/500 Accuracy: 89.1595238095238%\n",
      "Epoch 403/500 Accuracy: 89.1595238095238%\n",
      "Epoch 404/500 Accuracy: 89.16190476190476%\n",
      "Epoch 405/500 Accuracy: 89.16666666666667%\n",
      "Epoch 406/500 Accuracy: 89.17380952380952%\n",
      "Epoch 407/500 Accuracy: 89.18095238095238%\n",
      "Epoch 408/500 Accuracy: 89.18571428571428%\n",
      "Epoch 409/500 Accuracy: 89.19047619047619%\n",
      "Epoch 410/500 Accuracy: 89.19285714285714%\n",
      "Epoch 411/500 Accuracy: 89.1952380952381%\n",
      "Epoch 412/500 Accuracy: 89.2%\n",
      "Epoch 413/500 Accuracy: 89.2095238095238%\n",
      "Epoch 414/500 Accuracy: 89.21428571428571%\n",
      "Epoch 415/500 Accuracy: 89.21666666666667%\n",
      "Epoch 416/500 Accuracy: 89.22380952380952%\n",
      "Epoch 417/500 Accuracy: 89.23333333333333%\n",
      "Epoch 418/500 Accuracy: 89.23809523809524%\n",
      "Epoch 419/500 Accuracy: 89.2452380952381%\n",
      "Epoch 420/500 Accuracy: 89.25%\n",
      "Epoch 421/500 Accuracy: 89.25238095238095%\n",
      "Epoch 422/500 Accuracy: 89.26190476190476%\n",
      "Epoch 423/500 Accuracy: 89.26190476190476%\n",
      "Epoch 424/500 Accuracy: 89.26904761904761%\n",
      "Epoch 425/500 Accuracy: 89.27142857142857%\n",
      "Epoch 426/500 Accuracy: 89.27619047619048%\n",
      "Epoch 427/500 Accuracy: 89.27619047619048%\n",
      "Epoch 428/500 Accuracy: 89.27619047619048%\n",
      "Epoch 429/500 Accuracy: 89.29047619047618%\n",
      "Epoch 430/500 Accuracy: 89.29761904761905%\n",
      "Epoch 431/500 Accuracy: 89.30238095238096%\n",
      "Epoch 432/500 Accuracy: 89.30952380952381%\n",
      "Epoch 433/500 Accuracy: 89.30952380952381%\n",
      "Epoch 434/500 Accuracy: 89.31666666666666%\n",
      "Epoch 435/500 Accuracy: 89.31904761904762%\n",
      "Epoch 436/500 Accuracy: 89.32380952380953%\n",
      "Epoch 437/500 Accuracy: 89.32142857142857%\n",
      "Epoch 438/500 Accuracy: 89.32619047619048%\n",
      "Epoch 439/500 Accuracy: 89.33571428571429%\n",
      "Epoch 440/500 Accuracy: 89.33571428571429%\n",
      "Epoch 441/500 Accuracy: 89.33809523809524%\n",
      "Epoch 442/500 Accuracy: 89.3404761904762%\n",
      "Epoch 443/500 Accuracy: 89.3404761904762%\n",
      "Epoch 444/500 Accuracy: 89.3404761904762%\n",
      "Epoch 445/500 Accuracy: 89.34761904761905%\n",
      "Epoch 446/500 Accuracy: 89.35714285714286%\n",
      "Epoch 447/500 Accuracy: 89.35714285714286%\n",
      "Epoch 448/500 Accuracy: 89.36666666666667%\n",
      "Epoch 449/500 Accuracy: 89.37619047619047%\n",
      "Epoch 450/500 Accuracy: 89.37619047619047%\n",
      "Epoch 451/500 Accuracy: 89.37857142857143%\n",
      "Epoch 452/500 Accuracy: 89.38809523809523%\n",
      "Epoch 453/500 Accuracy: 89.38809523809523%\n",
      "Epoch 454/500 Accuracy: 89.39047619047619%\n",
      "Epoch 455/500 Accuracy: 89.39285714285714%\n",
      "Epoch 456/500 Accuracy: 89.4%\n",
      "Epoch 457/500 Accuracy: 89.40714285714286%\n",
      "Epoch 458/500 Accuracy: 89.4095238095238%\n",
      "Epoch 459/500 Accuracy: 89.40714285714286%\n",
      "Epoch 460/500 Accuracy: 89.4095238095238%\n",
      "Epoch 461/500 Accuracy: 89.41666666666667%\n",
      "Epoch 462/500 Accuracy: 89.42142857142858%\n",
      "Epoch 463/500 Accuracy: 89.42380952380952%\n",
      "Epoch 464/500 Accuracy: 89.42619047619048%\n",
      "Epoch 465/500 Accuracy: 89.42857142857143%\n",
      "Epoch 466/500 Accuracy: 89.43333333333334%\n",
      "Epoch 467/500 Accuracy: 89.43333333333334%\n",
      "Epoch 468/500 Accuracy: 89.43571428571428%\n",
      "Epoch 469/500 Accuracy: 89.43809523809524%\n",
      "Epoch 470/500 Accuracy: 89.44285714285715%\n",
      "Epoch 471/500 Accuracy: 89.44761904761904%\n",
      "Epoch 472/500 Accuracy: 89.45238095238095%\n",
      "Epoch 473/500 Accuracy: 89.45714285714286%\n",
      "Epoch 474/500 Accuracy: 89.45714285714286%\n",
      "Epoch 475/500 Accuracy: 89.46190476190476%\n",
      "Epoch 476/500 Accuracy: 89.46904761904761%\n",
      "Epoch 477/500 Accuracy: 89.47619047619048%\n",
      "Epoch 478/500 Accuracy: 89.47619047619048%\n",
      "Epoch 479/500 Accuracy: 89.48095238095239%\n",
      "Epoch 480/500 Accuracy: 89.47857142857143%\n",
      "Epoch 481/500 Accuracy: 89.47857142857143%\n",
      "Epoch 482/500 Accuracy: 89.4857142857143%\n",
      "Epoch 483/500 Accuracy: 89.48333333333333%\n",
      "Epoch 484/500 Accuracy: 89.48333333333333%\n",
      "Epoch 485/500 Accuracy: 89.49047619047619%\n",
      "Epoch 486/500 Accuracy: 89.49047619047619%\n",
      "Epoch 487/500 Accuracy: 89.49285714285715%\n",
      "Epoch 488/500 Accuracy: 89.5%\n",
      "Epoch 489/500 Accuracy: 89.49761904761905%\n",
      "Epoch 490/500 Accuracy: 89.5047619047619%\n",
      "Epoch 491/500 Accuracy: 89.5047619047619%\n",
      "Epoch 492/500 Accuracy: 89.5047619047619%\n",
      "Epoch 493/500 Accuracy: 89.5095238095238%\n",
      "Epoch 494/500 Accuracy: 89.5095238095238%\n",
      "Epoch 495/500 Accuracy: 89.50714285714285%\n",
      "Epoch 496/500 Accuracy: 89.5095238095238%\n",
      "Epoch 497/500 Accuracy: 89.51428571428572%\n",
      "Epoch 498/500 Accuracy: 89.51666666666667%\n",
      "Epoch 499/500 Accuracy: 89.52142857142857%\n",
      "Epoch 500/500 Accuracy: 89.52142857142857%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "import matplotlib.pyplot as plt\n",
    "#Importing libaries \n",
    "\n",
    "\n",
    "path = \"/kaggle/input/digit-recognizer/train.csv\"\n",
    "path1 = \"/kaggle/input/digit-recognizer/test.csv\"\n",
    "data = pd.read_csv(path, engine='c')\n",
    "test_data = pd.read_csv(path1, engine='c')\n",
    "test_data = test_data/255.0\n",
    "test_data = test_data.T\n",
    "label_1 = data['label']\n",
    "label_1 = label_1.T\n",
    "\n",
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "train_data = data[0:m].T\n",
    "X_train = train_data[1:n]\n",
    "X_train = X_train/255.0\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, input_dim=784, output_dim=10):\n",
    "        self.num_neurons = 256\n",
    "        self.batch_size = 256\n",
    "        \n",
    "        self.w_1 = np.random.randn(self.num_neurons, input_dim) * np.sqrt(2./input_dim)\n",
    "        self.w_2 = np.random.randn(self.num_neurons, self.num_neurons) * np.sqrt(2./10)\n",
    "        self.w_3 = np.random.randn(output_dim, self.num_neurons) * np.sqrt(2./10)\n",
    "        \n",
    "        self.b_1 = np.zeros((self.num_neurons, 1))\n",
    "        self.b_2 = np.zeros((self.num_neurons, 1))\n",
    "        self.b_3 = np.zeros((output_dim,1))\n",
    "        \n",
    "        self.learning_rate = 5e-6\n",
    "        self.epochs = 500\n",
    "        \n",
    "#Kaiming initialization, useful in normalisation of parameters and to prevent model being overfitting.\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return sci.special.expit(x)\n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        return np.where(x > 0, 1.0, 0.0)\n",
    "\n",
    "    def ELU(self, x):\n",
    "        return np.where(x >= 0.0, x, self.alpha * (np.exp(x) - 1))\n",
    "\n",
    "    def ELU_deriv(self,x):\n",
    "        return np.where(x >= 0, 1, self.alpha * np.exp(x))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        e_z = np.exp(z-np.max(z))\n",
    "        return sci.special.softmax(e_z)\n",
    "    \n",
    "    def softmax_backward(self,z):\n",
    "        do_dz = self.softmax(1-self.softmax)\n",
    "        \n",
    "    \n",
    "#Defining a set of activation functions for the convenience of changing act. functions below\n",
    "\n",
    "\n",
    "    def Forward(self, X_train):\n",
    "        self.sum_1 = np.dot(self.w_1, X_train) + self.b_1\n",
    "        self.output_1 = self.sigmoid(self.sum_1)\n",
    "        #First layer, using Sigmoid as activation\n",
    "\n",
    "        self.sum_2 = np.dot(self.w_2, self.output_1) + self.b_2\n",
    "        self.output_2 = self.sigmoid(self.sum_2)\n",
    "        #Second Layer, using Sigmoid as activation\n",
    "        \n",
    "        self.sum_3 = np.dot(self.w_3, self.output_2)+self.b_3\n",
    "        self.output_3 = self.sigmoid(self.sum_3)\n",
    "\n",
    "        self.predictions = np.argmax(self.output_3, axis=0)\n",
    "        return self.predictions\n",
    "    \n",
    "    #FeedForward Propagation, used to predict the label of the data.\n",
    "    \n",
    "    \n",
    "    def Backward(self, label_1, X_train):\n",
    "        \n",
    "        one_hot_labels = np.eye(10)[label_1].T\n",
    "        self.error = self.output_3 - one_hot_labels\n",
    "        self.delta_3 = self.error*self.sigmoid_derivative(self.output_3)\n",
    "        self.d_w_3 = np.dot(self.delta_3, self.output_2.T)  # Change output_3 to output_2\n",
    "        self.d_b_3 = np.sum(self.delta_3, axis=1, keepdims=True)\n",
    "    \n",
    "        self.delta_2 = np.dot(self.w_3.T, self.delta_3)*self.sigmoid_derivative(self.output_2)  # Change w_2 to w_3\n",
    "        self.d_w_2 = np.dot(self.delta_2, self.output_1.T)  # Change output_2 to output_1\n",
    "        self.d_b_2 = np.sum(self.delta_2, axis=1, keepdims=True)\n",
    "    \n",
    "        self.delta_1 = np.dot(self.w_2.T, self.delta_2) * self.sigmoid_derivative(self.output_1)  # Change w_1 to w_2\n",
    "        self.d_w_1 = np.dot(self.delta_1, X_train.T)\n",
    "        self.d_b_1 = np.sum(self.delta_1, axis=1, keepdims=True)\n",
    "        \n",
    "#Backwardpropagation, this program used gradient descent method to optimize the model\n",
    "        \n",
    "\n",
    "    def update_params(self):\n",
    "        self.w_1 -= self.learning_rate * self.d_w_1\n",
    "        self.w_2 -= self.learning_rate * self.d_w_2\n",
    "        self.w_3 -= self.learning_rate * self.d_w_3\n",
    "        \n",
    "        self.b_1 -= self.learning_rate * self.d_b_1\n",
    "        self.b_2 -= self.learning_rate * self.d_b_2\n",
    "        self.b_3 -= self.learning_rate * self.d_b_3\n",
    "        \n",
    "#Updating parameters\n",
    "\n",
    "    def compute_accuracy(self, label_1):\n",
    "        correct_predictions = np.sum(self.predictions == label_1)\n",
    "        total_predictions = self.predictions.shape[0]\n",
    "        self.accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "\n",
    "    def fit(self, X_train, label_1):\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            list_1 = list()\n",
    "            self.Forward(X_train)\n",
    "            self.Backward(label_1, X_train)\n",
    "            self.update_params()\n",
    "            self.compute_accuracy(label_1)\n",
    "            list_1.append(self.accuracy)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs} Accuracy: {self.accuracy * 100}%\")\n",
    "            #Create loop for training the mode\n",
    "        \n",
    "    def test(self,test_data):\n",
    "        result = []\n",
    "        self.Forward(test_data)\n",
    "        result.append(self.predictions)\n",
    "        result = pd.DataFrame(result)\n",
    "        result.head()\n",
    "        result = result.to_csv(\"/kaggle/working/submission.csv\")\n",
    "# Create an instance of the Model class\n",
    "model = Model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, label_1)\n",
    "model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfae08",
   "metadata": {
    "papermill": {
     "duration": 0.029701,
     "end_time": "2024-02-05T16:43:21.372702",
     "exception": false,
     "start_time": "2024-02-05T16:43:21.343001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98288b1",
   "metadata": {
    "papermill": {
     "duration": 0.029276,
     "end_time": "2024-02-05T16:43:21.431916",
     "exception": false,
     "start_time": "2024-02-05T16:43:21.402640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    },
    {
     "datasetId": 19,
     "sourceId": 420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 778.986205,
   "end_time": "2024-02-05T16:43:21.986865",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-05T16:30:23.000660",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
