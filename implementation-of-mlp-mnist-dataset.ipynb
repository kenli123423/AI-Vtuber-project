{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bba2e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-05T07:22:19.354186Z",
     "iopub.status.busy": "2024-02-05T07:22:19.353364Z",
     "iopub.status.idle": "2024-02-05T07:22:20.465788Z",
     "shell.execute_reply": "2024-02-05T07:22:20.464631Z"
    },
    "papermill": {
     "duration": 1.120781,
     "end_time": "2024-02-05T07:22:20.468897",
     "exception": false,
     "start_time": "2024-02-05T07:22:19.348116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/iris/Iris.csv\n",
      "/kaggle/input/iris/database.sqlite\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "d = pd.read_csv(\"/kaggle/input/iris/Iris.csv\")\n",
    "d.head()\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d55e4",
   "metadata": {
    "papermill": {
     "duration": 0.002556,
     "end_time": "2024-02-05T07:22:20.474775",
     "exception": false,
     "start_time": "2024-02-05T07:22:20.472219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a simple 2 layer MLP of the MNIST dataset classification, where sigmoid are used as activation functions of all layers.\n",
    "\n",
    "All 42000 images belong to 10 classes.\n",
    "\n",
    "# 1. FeedForward Propagation\n",
    "\n",
    "Output of the neuron follows :\n",
    "\n",
    "$\\sum = wx + b$\n",
    "\n",
    "$o = ReLu(\\sum)$\n",
    "\n",
    "Suppose $w_1,b_1$ be the weights and biases of the 1st layer, and $w_2, b_2$ be the weights and biases of the 2nd layer, thus, the output of each neuron in the output layer would be :\n",
    "\n",
    "$o_2 = softmax(w_2\\sum + b_2)$\n",
    "\n",
    "# 2. BackwardPropagation\n",
    "\n",
    "This algorithm uses gradient descent method as optimization method.\n",
    "\n",
    "Suppose $\\delta_1$ and $\\delta_2$ be the **error** of 1st and 2nd layer respectively, $\\vec t_m = (t_1,t_2,....,t_m)$ and $\\vec y_m = (y_1, y_2,....,y_m)$ be the target and output vector respectively, we have in the second layer :\n",
    "\n",
    "$\\delta_2 = \\frac{\\partial E}{\\partial w_ij} = (y_i - t_i)$\n",
    "\n",
    "Hence the correction of weight in each iteration should be :\n",
    "\n",
    "$\\vardelta_ij = \n",
    "\n",
    "# 3. Activation Functions\n",
    "\n",
    "1. ReLu\n",
    "- Relu is the most popular activation function in machine learning, it is defined as :\n",
    "\n",
    "$ReLu(x) = x$ for x>0\n",
    "\n",
    "$ReLu(x) = 0$ for x<0\n",
    "\n",
    "Relu is famous of it's simplifcity of it's derivative function, the derivative of ReLu is :\n",
    "\n",
    "$ReLU'(x) = 0$ for x<0\n",
    "\n",
    "$ReLU'(x) = 1$ for x>0\n",
    "\n",
    "2. Softmax\n",
    "- Softmax is another popular activation function, it can helps transform the output into probability, the softmax function is defined as :\n",
    "\n",
    "$softmax(z)_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc560d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T07:22:20.482391Z",
     "iopub.status.busy": "2024-02-05T07:22:20.481910Z",
     "iopub.status.idle": "2024-02-05T07:47:46.785322Z",
     "shell.execute_reply": "2024-02-05T07:47:46.784041Z"
    },
    "papermill": {
     "duration": 1526.311404,
     "end_time": "2024-02-05T07:47:46.788901",
     "exception": false,
     "start_time": "2024-02-05T07:22:20.477497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600 Accuracy: 10.47857142857143%\n",
      "Epoch 2/600 Accuracy: 33.87619047619047%\n",
      "Epoch 3/600 Accuracy: 10.359523809523811%\n",
      "Epoch 4/600 Accuracy: 10.359523809523811%\n",
      "Epoch 5/600 Accuracy: 14.892857142857144%\n",
      "Epoch 6/600 Accuracy: 21.419047619047618%\n",
      "Epoch 7/600 Accuracy: 24.68095238095238%\n",
      "Epoch 8/600 Accuracy: 38.93809523809524%\n",
      "Epoch 9/600 Accuracy: 18.714285714285715%\n",
      "Epoch 10/600 Accuracy: 22.03333333333333%\n",
      "Epoch 11/600 Accuracy: 33.78809523809524%\n",
      "Epoch 12/600 Accuracy: 13.347619047619046%\n",
      "Epoch 13/600 Accuracy: 20.202380952380953%\n",
      "Epoch 14/600 Accuracy: 18.96904761904762%\n",
      "Epoch 15/600 Accuracy: 46.635714285714286%\n",
      "Epoch 16/600 Accuracy: 67.58809523809524%\n",
      "Epoch 17/600 Accuracy: 68.96904761904761%\n",
      "Epoch 18/600 Accuracy: 69.24761904761905%\n",
      "Epoch 19/600 Accuracy: 75.4095238095238%\n",
      "Epoch 20/600 Accuracy: 76.44999999999999%\n",
      "Epoch 21/600 Accuracy: 79.69047619047619%\n",
      "Epoch 22/600 Accuracy: 78.99047619047619%\n",
      "Epoch 23/600 Accuracy: 81.79761904761905%\n",
      "Epoch 24/600 Accuracy: 81.42142857142856%\n",
      "Epoch 25/600 Accuracy: 83.20476190476191%\n",
      "Epoch 26/600 Accuracy: 83.05952380952381%\n",
      "Epoch 27/600 Accuracy: 84.20238095238095%\n",
      "Epoch 28/600 Accuracy: 84.16428571428571%\n",
      "Epoch 29/600 Accuracy: 84.87380952380953%\n",
      "Epoch 30/600 Accuracy: 84.91428571428571%\n",
      "Epoch 31/600 Accuracy: 85.41190476190476%\n",
      "Epoch 32/600 Accuracy: 85.52857142857142%\n",
      "Epoch 33/600 Accuracy: 85.86666666666667%\n",
      "Epoch 34/600 Accuracy: 86.0%\n",
      "Epoch 35/600 Accuracy: 86.28333333333333%\n",
      "Epoch 36/600 Accuracy: 86.3547619047619%\n",
      "Epoch 37/600 Accuracy: 86.55000000000001%\n",
      "Epoch 38/600 Accuracy: 86.68571428571428%\n",
      "Epoch 39/600 Accuracy: 86.8452380952381%\n",
      "Epoch 40/600 Accuracy: 86.9595238095238%\n",
      "Epoch 41/600 Accuracy: 87.07619047619048%\n",
      "Epoch 42/600 Accuracy: 87.17142857142856%\n",
      "Epoch 43/600 Accuracy: 87.29285714285714%\n",
      "Epoch 44/600 Accuracy: 87.39761904761905%\n",
      "Epoch 45/600 Accuracy: 87.49047619047619%\n",
      "Epoch 46/600 Accuracy: 87.57142857142857%\n",
      "Epoch 47/600 Accuracy: 87.66428571428571%\n",
      "Epoch 48/600 Accuracy: 87.71190476190476%\n",
      "Epoch 49/600 Accuracy: 87.76190476190476%\n",
      "Epoch 50/600 Accuracy: 87.82380952380953%\n",
      "Epoch 51/600 Accuracy: 87.90714285714286%\n",
      "Epoch 52/600 Accuracy: 88.0142857142857%\n",
      "Epoch 53/600 Accuracy: 88.08095238095238%\n",
      "Epoch 54/600 Accuracy: 88.17619047619047%\n",
      "Epoch 55/600 Accuracy: 88.22857142857143%\n",
      "Epoch 56/600 Accuracy: 88.3%\n",
      "Epoch 57/600 Accuracy: 88.37380952380953%\n",
      "Epoch 58/600 Accuracy: 88.45238095238095%\n",
      "Epoch 59/600 Accuracy: 88.49285714285713%\n",
      "Epoch 60/600 Accuracy: 88.56428571428572%\n",
      "Epoch 61/600 Accuracy: 88.62857142857142%\n",
      "Epoch 62/600 Accuracy: 88.68095238095238%\n",
      "Epoch 63/600 Accuracy: 88.73333333333333%\n",
      "Epoch 64/600 Accuracy: 88.78571428571429%\n",
      "Epoch 65/600 Accuracy: 88.84285714285714%\n",
      "Epoch 66/600 Accuracy: 88.88809523809523%\n",
      "Epoch 67/600 Accuracy: 88.93095238095238%\n",
      "Epoch 68/600 Accuracy: 88.96666666666667%\n",
      "Epoch 69/600 Accuracy: 89.0142857142857%\n",
      "Epoch 70/600 Accuracy: 89.05238095238094%\n",
      "Epoch 71/600 Accuracy: 89.09523809523809%\n",
      "Epoch 72/600 Accuracy: 89.14285714285714%\n",
      "Epoch 73/600 Accuracy: 89.18809523809523%\n",
      "Epoch 74/600 Accuracy: 89.21904761904761%\n",
      "Epoch 75/600 Accuracy: 89.2547619047619%\n",
      "Epoch 76/600 Accuracy: 89.30238095238096%\n",
      "Epoch 77/600 Accuracy: 89.3404761904762%\n",
      "Epoch 78/600 Accuracy: 89.37142857142857%\n",
      "Epoch 79/600 Accuracy: 89.40714285714286%\n",
      "Epoch 80/600 Accuracy: 89.43809523809524%\n",
      "Epoch 81/600 Accuracy: 89.46428571428572%\n",
      "Epoch 82/600 Accuracy: 89.49047619047619%\n",
      "Epoch 83/600 Accuracy: 89.5095238095238%\n",
      "Epoch 84/600 Accuracy: 89.55952380952381%\n",
      "Epoch 85/600 Accuracy: 89.58571428571429%\n",
      "Epoch 86/600 Accuracy: 89.62142857142858%\n",
      "Epoch 87/600 Accuracy: 89.6547619047619%\n",
      "Epoch 88/600 Accuracy: 89.67142857142856%\n",
      "Epoch 89/600 Accuracy: 89.70238095238095%\n",
      "Epoch 90/600 Accuracy: 89.73095238095237%\n",
      "Epoch 91/600 Accuracy: 89.75714285714285%\n",
      "Epoch 92/600 Accuracy: 89.77857142857142%\n",
      "Epoch 93/600 Accuracy: 89.80714285714285%\n",
      "Epoch 94/600 Accuracy: 89.8452380952381%\n",
      "Epoch 95/600 Accuracy: 89.87142857142857%\n",
      "Epoch 96/600 Accuracy: 89.90714285714286%\n",
      "Epoch 97/600 Accuracy: 89.93809523809524%\n",
      "Epoch 98/600 Accuracy: 89.96904761904761%\n",
      "Epoch 99/600 Accuracy: 89.99761904761905%\n",
      "Epoch 100/600 Accuracy: 90.02619047619046%\n",
      "Epoch 101/600 Accuracy: 90.06190476190477%\n",
      "Epoch 102/600 Accuracy: 90.08333333333334%\n",
      "Epoch 103/600 Accuracy: 90.10714285714285%\n",
      "Epoch 104/600 Accuracy: 90.12619047619047%\n",
      "Epoch 105/600 Accuracy: 90.14285714285715%\n",
      "Epoch 106/600 Accuracy: 90.17380952380952%\n",
      "Epoch 107/600 Accuracy: 90.1952380952381%\n",
      "Epoch 108/600 Accuracy: 90.20714285714286%\n",
      "Epoch 109/600 Accuracy: 90.23571428571428%\n",
      "Epoch 110/600 Accuracy: 90.26190476190476%\n",
      "Epoch 111/600 Accuracy: 90.29285714285714%\n",
      "Epoch 112/600 Accuracy: 90.31904761904762%\n",
      "Epoch 113/600 Accuracy: 90.33333333333333%\n",
      "Epoch 114/600 Accuracy: 90.3547619047619%\n",
      "Epoch 115/600 Accuracy: 90.38333333333334%\n",
      "Epoch 116/600 Accuracy: 90.40238095238095%\n",
      "Epoch 117/600 Accuracy: 90.41666666666667%\n",
      "Epoch 118/600 Accuracy: 90.44761904761904%\n",
      "Epoch 119/600 Accuracy: 90.45952380952382%\n",
      "Epoch 120/600 Accuracy: 90.46190476190476%\n",
      "Epoch 121/600 Accuracy: 90.47380952380952%\n",
      "Epoch 122/600 Accuracy: 90.50714285714285%\n",
      "Epoch 123/600 Accuracy: 90.52142857142857%\n",
      "Epoch 124/600 Accuracy: 90.52619047619046%\n",
      "Epoch 125/600 Accuracy: 90.53333333333333%\n",
      "Epoch 126/600 Accuracy: 90.57619047619048%\n",
      "Epoch 127/600 Accuracy: 90.5952380952381%\n",
      "Epoch 128/600 Accuracy: 90.62380952380953%\n",
      "Epoch 129/600 Accuracy: 90.64047619047619%\n",
      "Epoch 130/600 Accuracy: 90.66190476190476%\n",
      "Epoch 131/600 Accuracy: 90.68333333333334%\n",
      "Epoch 132/600 Accuracy: 90.69761904761904%\n",
      "Epoch 133/600 Accuracy: 90.72380952380954%\n",
      "Epoch 134/600 Accuracy: 90.73095238095237%\n",
      "Epoch 135/600 Accuracy: 90.74761904761904%\n",
      "Epoch 136/600 Accuracy: 90.76428571428572%\n",
      "Epoch 137/600 Accuracy: 90.76190476190476%\n",
      "Epoch 138/600 Accuracy: 90.77857142857142%\n",
      "Epoch 139/600 Accuracy: 90.79285714285714%\n",
      "Epoch 140/600 Accuracy: 90.8047619047619%\n",
      "Epoch 141/600 Accuracy: 90.82142857142857%\n",
      "Epoch 142/600 Accuracy: 90.84761904761905%\n",
      "Epoch 143/600 Accuracy: 90.85238095238095%\n",
      "Epoch 144/600 Accuracy: 90.86190476190477%\n",
      "Epoch 145/600 Accuracy: 90.87142857142857%\n",
      "Epoch 146/600 Accuracy: 90.88095238095238%\n",
      "Epoch 147/600 Accuracy: 90.9%\n",
      "Epoch 148/600 Accuracy: 90.91428571428571%\n",
      "Epoch 149/600 Accuracy: 90.92142857142858%\n",
      "Epoch 150/600 Accuracy: 90.92142857142858%\n",
      "Epoch 151/600 Accuracy: 90.92857142857143%\n",
      "Epoch 152/600 Accuracy: 90.94285714285715%\n",
      "Epoch 153/600 Accuracy: 90.95238095238095%\n",
      "Epoch 154/600 Accuracy: 90.95952380952382%\n",
      "Epoch 155/600 Accuracy: 90.97380952380952%\n",
      "Epoch 156/600 Accuracy: 90.98333333333333%\n",
      "Epoch 157/600 Accuracy: 90.9952380952381%\n",
      "Epoch 158/600 Accuracy: 91.00952380952381%\n",
      "Epoch 159/600 Accuracy: 91.01904761904763%\n",
      "Epoch 160/600 Accuracy: 91.0404761904762%\n",
      "Epoch 161/600 Accuracy: 91.04285714285714%\n",
      "Epoch 162/600 Accuracy: 91.05%\n",
      "Epoch 163/600 Accuracy: 91.05714285714286%\n",
      "Epoch 164/600 Accuracy: 91.07380952380953%\n",
      "Epoch 165/600 Accuracy: 91.09285714285714%\n",
      "Epoch 166/600 Accuracy: 91.11428571428571%\n",
      "Epoch 167/600 Accuracy: 91.13095238095238%\n",
      "Epoch 168/600 Accuracy: 91.13571428571429%\n",
      "Epoch 169/600 Accuracy: 91.13571428571429%\n",
      "Epoch 170/600 Accuracy: 91.14285714285715%\n",
      "Epoch 171/600 Accuracy: 91.14285714285715%\n",
      "Epoch 172/600 Accuracy: 91.15952380952382%\n",
      "Epoch 173/600 Accuracy: 91.16904761904762%\n",
      "Epoch 174/600 Accuracy: 91.17619047619047%\n",
      "Epoch 175/600 Accuracy: 91.18809523809523%\n",
      "Epoch 176/600 Accuracy: 91.21428571428571%\n",
      "Epoch 177/600 Accuracy: 91.23333333333333%\n",
      "Epoch 178/600 Accuracy: 91.2642857142857%\n",
      "Epoch 179/600 Accuracy: 91.27857142857142%\n",
      "Epoch 180/600 Accuracy: 91.28333333333333%\n",
      "Epoch 181/600 Accuracy: 91.29761904761905%\n",
      "Epoch 182/600 Accuracy: 91.31428571428572%\n",
      "Epoch 183/600 Accuracy: 91.32380952380953%\n",
      "Epoch 184/600 Accuracy: 91.33095238095238%\n",
      "Epoch 185/600 Accuracy: 91.33809523809524%\n",
      "Epoch 186/600 Accuracy: 91.35%\n",
      "Epoch 187/600 Accuracy: 91.35714285714286%\n",
      "Epoch 188/600 Accuracy: 91.37857142857143%\n",
      "Epoch 189/600 Accuracy: 91.38571428571429%\n",
      "Epoch 190/600 Accuracy: 91.39761904761905%\n",
      "Epoch 191/600 Accuracy: 91.41190476190476%\n",
      "Epoch 192/600 Accuracy: 91.42142857142858%\n",
      "Epoch 193/600 Accuracy: 91.42619047619047%\n",
      "Epoch 194/600 Accuracy: 91.43095238095238%\n",
      "Epoch 195/600 Accuracy: 91.44047619047619%\n",
      "Epoch 196/600 Accuracy: 91.45238095238095%\n",
      "Epoch 197/600 Accuracy: 91.46904761904761%\n",
      "Epoch 198/600 Accuracy: 91.47619047619048%\n",
      "Epoch 199/600 Accuracy: 91.49047619047619%\n",
      "Epoch 200/600 Accuracy: 91.49761904761905%\n",
      "Epoch 201/600 Accuracy: 91.49761904761905%\n",
      "Epoch 202/600 Accuracy: 91.5%\n",
      "Epoch 203/600 Accuracy: 91.51904761904763%\n",
      "Epoch 204/600 Accuracy: 91.52619047619048%\n",
      "Epoch 205/600 Accuracy: 91.53333333333333%\n",
      "Epoch 206/600 Accuracy: 91.5404761904762%\n",
      "Epoch 207/600 Accuracy: 91.54761904761905%\n",
      "Epoch 208/600 Accuracy: 91.54761904761905%\n",
      "Epoch 209/600 Accuracy: 91.55%\n",
      "Epoch 210/600 Accuracy: 91.55952380952381%\n",
      "Epoch 211/600 Accuracy: 91.55714285714286%\n",
      "Epoch 212/600 Accuracy: 91.56666666666666%\n",
      "Epoch 213/600 Accuracy: 91.55952380952381%\n",
      "Epoch 214/600 Accuracy: 91.56904761904762%\n",
      "Epoch 215/600 Accuracy: 91.58095238095238%\n",
      "Epoch 216/600 Accuracy: 91.58571428571427%\n",
      "Epoch 217/600 Accuracy: 91.5904761904762%\n",
      "Epoch 218/600 Accuracy: 91.5952380952381%\n",
      "Epoch 219/600 Accuracy: 91.60952380952381%\n",
      "Epoch 220/600 Accuracy: 91.62142857142858%\n",
      "Epoch 221/600 Accuracy: 91.62142857142858%\n",
      "Epoch 222/600 Accuracy: 91.63809523809525%\n",
      "Epoch 223/600 Accuracy: 91.64285714285715%\n",
      "Epoch 224/600 Accuracy: 91.64999999999999%\n",
      "Epoch 225/600 Accuracy: 91.66666666666666%\n",
      "Epoch 226/600 Accuracy: 91.67619047619048%\n",
      "Epoch 227/600 Accuracy: 91.68095238095239%\n",
      "Epoch 228/600 Accuracy: 91.68333333333332%\n",
      "Epoch 229/600 Accuracy: 91.7%\n",
      "Epoch 230/600 Accuracy: 91.71190476190476%\n",
      "Epoch 231/600 Accuracy: 91.71666666666667%\n",
      "Epoch 232/600 Accuracy: 91.71904761904763%\n",
      "Epoch 233/600 Accuracy: 91.73333333333333%\n",
      "Epoch 234/600 Accuracy: 91.73809523809524%\n",
      "Epoch 235/600 Accuracy: 91.7452380952381%\n",
      "Epoch 236/600 Accuracy: 91.74761904761904%\n",
      "Epoch 237/600 Accuracy: 91.76904761904761%\n",
      "Epoch 238/600 Accuracy: 91.76904761904761%\n",
      "Epoch 239/600 Accuracy: 91.76904761904761%\n",
      "Epoch 240/600 Accuracy: 91.77857142857142%\n",
      "Epoch 241/600 Accuracy: 91.79285714285714%\n",
      "Epoch 242/600 Accuracy: 91.79047619047618%\n",
      "Epoch 243/600 Accuracy: 91.79047619047618%\n",
      "Epoch 244/600 Accuracy: 91.79285714285714%\n",
      "Epoch 245/600 Accuracy: 91.80238095238096%\n",
      "Epoch 246/600 Accuracy: 91.81428571428572%\n",
      "Epoch 247/600 Accuracy: 91.80952380952381%\n",
      "Epoch 248/600 Accuracy: 91.80952380952381%\n",
      "Epoch 249/600 Accuracy: 91.82142857142857%\n",
      "Epoch 250/600 Accuracy: 91.82619047619048%\n",
      "Epoch 251/600 Accuracy: 91.83333333333333%\n",
      "Epoch 252/600 Accuracy: 91.84761904761905%\n",
      "Epoch 253/600 Accuracy: 91.85238095238095%\n",
      "Epoch 254/600 Accuracy: 91.8547619047619%\n",
      "Epoch 255/600 Accuracy: 91.86428571428571%\n",
      "Epoch 256/600 Accuracy: 91.88095238095238%\n",
      "Epoch 257/600 Accuracy: 91.89047619047619%\n",
      "Epoch 258/600 Accuracy: 91.89761904761905%\n",
      "Epoch 259/600 Accuracy: 91.9047619047619%\n",
      "Epoch 260/600 Accuracy: 91.90714285714286%\n",
      "Epoch 261/600 Accuracy: 91.9047619047619%\n",
      "Epoch 262/600 Accuracy: 91.91904761904762%\n",
      "Epoch 263/600 Accuracy: 91.92857142857143%\n",
      "Epoch 264/600 Accuracy: 91.93571428571428%\n",
      "Epoch 265/600 Accuracy: 91.94761904761904%\n",
      "Epoch 266/600 Accuracy: 91.95%\n",
      "Epoch 267/600 Accuracy: 91.96190476190476%\n",
      "Epoch 268/600 Accuracy: 91.96904761904761%\n",
      "Epoch 269/600 Accuracy: 91.96666666666667%\n",
      "Epoch 270/600 Accuracy: 91.97380952380952%\n",
      "Epoch 271/600 Accuracy: 91.98095238095239%\n",
      "Epoch 272/600 Accuracy: 91.99047619047619%\n",
      "Epoch 273/600 Accuracy: 91.99047619047619%\n",
      "Epoch 274/600 Accuracy: 91.98809523809524%\n",
      "Epoch 275/600 Accuracy: 91.98333333333333%\n",
      "Epoch 276/600 Accuracy: 91.99047619047619%\n",
      "Epoch 277/600 Accuracy: 91.99285714285715%\n",
      "Epoch 278/600 Accuracy: 91.99285714285715%\n",
      "Epoch 279/600 Accuracy: 91.99761904761905%\n",
      "Epoch 280/600 Accuracy: 92.0%\n",
      "Epoch 281/600 Accuracy: 92.0047619047619%\n",
      "Epoch 282/600 Accuracy: 92.00714285714285%\n",
      "Epoch 283/600 Accuracy: 92.01428571428572%\n",
      "Epoch 284/600 Accuracy: 92.01666666666667%\n",
      "Epoch 285/600 Accuracy: 92.02619047619048%\n",
      "Epoch 286/600 Accuracy: 92.03333333333333%\n",
      "Epoch 287/600 Accuracy: 92.02380952380952%\n",
      "Epoch 288/600 Accuracy: 92.02142857142857%\n",
      "Epoch 289/600 Accuracy: 92.02619047619048%\n",
      "Epoch 290/600 Accuracy: 92.03095238095239%\n",
      "Epoch 291/600 Accuracy: 92.03333333333333%\n",
      "Epoch 292/600 Accuracy: 92.03333333333333%\n",
      "Epoch 293/600 Accuracy: 92.03571428571429%\n",
      "Epoch 294/600 Accuracy: 92.03571428571429%\n",
      "Epoch 295/600 Accuracy: 92.03809523809524%\n",
      "Epoch 296/600 Accuracy: 92.0404761904762%\n",
      "Epoch 297/600 Accuracy: 92.04285714285714%\n",
      "Epoch 298/600 Accuracy: 92.04285714285714%\n",
      "Epoch 299/600 Accuracy: 92.0547619047619%\n",
      "Epoch 300/600 Accuracy: 92.06904761904762%\n",
      "Epoch 301/600 Accuracy: 92.08095238095238%\n",
      "Epoch 302/600 Accuracy: 92.08809523809524%\n",
      "Epoch 303/600 Accuracy: 92.0904761904762%\n",
      "Epoch 304/600 Accuracy: 92.08809523809524%\n",
      "Epoch 305/600 Accuracy: 92.0952380952381%\n",
      "Epoch 306/600 Accuracy: 92.10000000000001%\n",
      "Epoch 307/600 Accuracy: 92.10238095238095%\n",
      "Epoch 308/600 Accuracy: 92.11190476190477%\n",
      "Epoch 309/600 Accuracy: 92.11428571428571%\n",
      "Epoch 310/600 Accuracy: 92.11904761904762%\n",
      "Epoch 311/600 Accuracy: 92.12857142857143%\n",
      "Epoch 312/600 Accuracy: 92.13571428571429%\n",
      "Epoch 313/600 Accuracy: 92.14285714285714%\n",
      "Epoch 314/600 Accuracy: 92.14761904761905%\n",
      "Epoch 315/600 Accuracy: 92.15952380952382%\n",
      "Epoch 316/600 Accuracy: 92.16428571428571%\n",
      "Epoch 317/600 Accuracy: 92.16904761904762%\n",
      "Epoch 318/600 Accuracy: 92.17380952380952%\n",
      "Epoch 319/600 Accuracy: 92.17380952380952%\n",
      "Epoch 320/600 Accuracy: 92.17857142857143%\n",
      "Epoch 321/600 Accuracy: 92.18095238095239%\n",
      "Epoch 322/600 Accuracy: 92.18333333333332%\n",
      "Epoch 323/600 Accuracy: 92.18571428571428%\n",
      "Epoch 324/600 Accuracy: 92.18809523809523%\n",
      "Epoch 325/600 Accuracy: 92.19047619047619%\n",
      "Epoch 326/600 Accuracy: 92.19761904761906%\n",
      "Epoch 327/600 Accuracy: 92.1952380952381%\n",
      "Epoch 328/600 Accuracy: 92.2047619047619%\n",
      "Epoch 329/600 Accuracy: 92.2095238095238%\n",
      "Epoch 330/600 Accuracy: 92.21190476190476%\n",
      "Epoch 331/600 Accuracy: 92.21428571428572%\n",
      "Epoch 332/600 Accuracy: 92.22380952380952%\n",
      "Epoch 333/600 Accuracy: 92.22380952380952%\n",
      "Epoch 334/600 Accuracy: 92.23809523809524%\n",
      "Epoch 335/600 Accuracy: 92.24285714285713%\n",
      "Epoch 336/600 Accuracy: 92.24761904761904%\n",
      "Epoch 337/600 Accuracy: 92.2547619047619%\n",
      "Epoch 338/600 Accuracy: 92.25952380952381%\n",
      "Epoch 339/600 Accuracy: 92.27142857142857%\n",
      "Epoch 340/600 Accuracy: 92.27380952380952%\n",
      "Epoch 341/600 Accuracy: 92.27142857142857%\n",
      "Epoch 342/600 Accuracy: 92.28095238095239%\n",
      "Epoch 343/600 Accuracy: 92.28809523809524%\n",
      "Epoch 344/600 Accuracy: 92.29047619047618%\n",
      "Epoch 345/600 Accuracy: 92.29047619047618%\n",
      "Epoch 346/600 Accuracy: 92.29523809523809%\n",
      "Epoch 347/600 Accuracy: 92.29761904761905%\n",
      "Epoch 348/600 Accuracy: 92.3047619047619%\n",
      "Epoch 349/600 Accuracy: 92.3047619047619%\n",
      "Epoch 350/600 Accuracy: 92.31190476190476%\n",
      "Epoch 351/600 Accuracy: 92.31190476190476%\n",
      "Epoch 352/600 Accuracy: 92.31666666666666%\n",
      "Epoch 353/600 Accuracy: 92.31666666666666%\n",
      "Epoch 354/600 Accuracy: 92.31904761904762%\n",
      "Epoch 355/600 Accuracy: 92.32857142857142%\n",
      "Epoch 356/600 Accuracy: 92.32857142857142%\n",
      "Epoch 357/600 Accuracy: 92.3404761904762%\n",
      "Epoch 358/600 Accuracy: 92.3547619047619%\n",
      "Epoch 359/600 Accuracy: 92.35238095238095%\n",
      "Epoch 360/600 Accuracy: 92.3547619047619%\n",
      "Epoch 361/600 Accuracy: 92.35714285714286%\n",
      "Epoch 362/600 Accuracy: 92.3547619047619%\n",
      "Epoch 363/600 Accuracy: 92.36190476190477%\n",
      "Epoch 364/600 Accuracy: 92.35952380952381%\n",
      "Epoch 365/600 Accuracy: 92.36428571428571%\n",
      "Epoch 366/600 Accuracy: 92.36666666666666%\n",
      "Epoch 367/600 Accuracy: 92.37380952380953%\n",
      "Epoch 368/600 Accuracy: 92.36904761904762%\n",
      "Epoch 369/600 Accuracy: 92.37142857142857%\n",
      "Epoch 370/600 Accuracy: 92.37857142857143%\n",
      "Epoch 371/600 Accuracy: 92.38095238095238%\n",
      "Epoch 372/600 Accuracy: 92.38809523809523%\n",
      "Epoch 373/600 Accuracy: 92.38809523809523%\n",
      "Epoch 374/600 Accuracy: 92.39285714285714%\n",
      "Epoch 375/600 Accuracy: 92.40238095238095%\n",
      "Epoch 376/600 Accuracy: 92.40714285714286%\n",
      "Epoch 377/600 Accuracy: 92.41190476190476%\n",
      "Epoch 378/600 Accuracy: 92.41904761904762%\n",
      "Epoch 379/600 Accuracy: 92.42380952380952%\n",
      "Epoch 380/600 Accuracy: 92.43333333333334%\n",
      "Epoch 381/600 Accuracy: 92.43809523809524%\n",
      "Epoch 382/600 Accuracy: 92.4452380952381%\n",
      "Epoch 383/600 Accuracy: 92.44285714285714%\n",
      "Epoch 384/600 Accuracy: 92.45%\n",
      "Epoch 385/600 Accuracy: 92.45238095238095%\n",
      "Epoch 386/600 Accuracy: 92.46190476190476%\n",
      "Epoch 387/600 Accuracy: 92.47380952380952%\n",
      "Epoch 388/600 Accuracy: 92.47142857142858%\n",
      "Epoch 389/600 Accuracy: 92.47380952380952%\n",
      "Epoch 390/600 Accuracy: 92.47619047619048%\n",
      "Epoch 391/600 Accuracy: 92.47857142857143%\n",
      "Epoch 392/600 Accuracy: 92.48333333333333%\n",
      "Epoch 393/600 Accuracy: 92.48571428571428%\n",
      "Epoch 394/600 Accuracy: 92.48571428571428%\n",
      "Epoch 395/600 Accuracy: 92.48571428571428%\n",
      "Epoch 396/600 Accuracy: 92.48809523809524%\n",
      "Epoch 397/600 Accuracy: 92.49047619047619%\n",
      "Epoch 398/600 Accuracy: 92.4952380952381%\n",
      "Epoch 399/600 Accuracy: 92.4952380952381%\n",
      "Epoch 400/600 Accuracy: 92.49761904761905%\n",
      "Epoch 401/600 Accuracy: 92.50952380952381%\n",
      "Epoch 402/600 Accuracy: 92.50952380952381%\n",
      "Epoch 403/600 Accuracy: 92.51190476190476%\n",
      "Epoch 404/600 Accuracy: 92.51904761904763%\n",
      "Epoch 405/600 Accuracy: 92.52142857142857%\n",
      "Epoch 406/600 Accuracy: 92.53809523809524%\n",
      "Epoch 407/600 Accuracy: 92.54761904761905%\n",
      "Epoch 408/600 Accuracy: 92.55952380952381%\n",
      "Epoch 409/600 Accuracy: 92.57142857142857%\n",
      "Epoch 410/600 Accuracy: 92.56428571428572%\n",
      "Epoch 411/600 Accuracy: 92.56666666666666%\n",
      "Epoch 412/600 Accuracy: 92.56904761904762%\n",
      "Epoch 413/600 Accuracy: 92.57619047619048%\n",
      "Epoch 414/600 Accuracy: 92.56666666666666%\n",
      "Epoch 415/600 Accuracy: 92.58095238095238%\n",
      "Epoch 416/600 Accuracy: 92.58571428571429%\n",
      "Epoch 417/600 Accuracy: 92.58095238095238%\n",
      "Epoch 418/600 Accuracy: 92.57380952380953%\n",
      "Epoch 419/600 Accuracy: 92.59285714285714%\n",
      "Epoch 420/600 Accuracy: 92.57857142857144%\n",
      "Epoch 421/600 Accuracy: 92.57619047619048%\n",
      "Epoch 422/600 Accuracy: 92.61190476190477%\n",
      "Epoch 423/600 Accuracy: 92.56666666666666%\n",
      "Epoch 424/600 Accuracy: 92.64285714285714%\n",
      "Epoch 425/600 Accuracy: 92.5047619047619%\n",
      "Epoch 426/600 Accuracy: 92.61190476190477%\n",
      "Epoch 427/600 Accuracy: 92.36428571428571%\n",
      "Epoch 428/600 Accuracy: 92.40714285714286%\n",
      "Epoch 429/600 Accuracy: 91.85714285714286%\n",
      "Epoch 430/600 Accuracy: 91.64047619047619%\n",
      "Epoch 431/600 Accuracy: 88.91666666666667%\n",
      "Epoch 432/600 Accuracy: 88.17857142857143%\n",
      "Epoch 433/600 Accuracy: 71.80238095238096%\n",
      "Epoch 434/600 Accuracy: 85.29285714285714%\n",
      "Epoch 435/600 Accuracy: 73.4952380952381%\n",
      "Epoch 436/600 Accuracy: 88.60952380952381%\n",
      "Epoch 437/600 Accuracy: 80.77380952380952%\n",
      "Epoch 438/600 Accuracy: 87.89047619047619%\n",
      "Epoch 439/600 Accuracy: 89.52142857142857%\n",
      "Epoch 440/600 Accuracy: 91.66904761904762%\n",
      "Epoch 441/600 Accuracy: 92.00714285714285%\n",
      "Epoch 442/600 Accuracy: 92.22142857142858%\n",
      "Epoch 443/600 Accuracy: 92.27142857142857%\n",
      "Epoch 444/600 Accuracy: 92.32142857142858%\n",
      "Epoch 445/600 Accuracy: 92.33809523809524%\n",
      "Epoch 446/600 Accuracy: 92.34761904761905%\n",
      "Epoch 447/600 Accuracy: 92.38571428571429%\n",
      "Epoch 448/600 Accuracy: 92.41190476190476%\n",
      "Epoch 449/600 Accuracy: 92.41428571428571%\n",
      "Epoch 450/600 Accuracy: 92.45%\n",
      "Epoch 451/600 Accuracy: 92.41904761904762%\n",
      "Epoch 452/600 Accuracy: 92.4452380952381%\n",
      "Epoch 453/600 Accuracy: 92.44761904761904%\n",
      "Epoch 454/600 Accuracy: 92.48095238095239%\n",
      "Epoch 455/600 Accuracy: 92.48571428571428%\n",
      "Epoch 456/600 Accuracy: 92.52380952380952%\n",
      "Epoch 457/600 Accuracy: 92.51428571428572%\n",
      "Epoch 458/600 Accuracy: 92.54285714285714%\n",
      "Epoch 459/600 Accuracy: 92.54285714285714%\n",
      "Epoch 460/600 Accuracy: 92.55%\n",
      "Epoch 461/600 Accuracy: 92.55%\n",
      "Epoch 462/600 Accuracy: 92.56190476190476%\n",
      "Epoch 463/600 Accuracy: 92.57619047619048%\n",
      "Epoch 464/600 Accuracy: 92.58571428571429%\n",
      "Epoch 465/600 Accuracy: 92.58809523809524%\n",
      "Epoch 466/600 Accuracy: 92.59285714285714%\n",
      "Epoch 467/600 Accuracy: 92.58809523809524%\n",
      "Epoch 468/600 Accuracy: 92.59285714285714%\n",
      "Epoch 469/600 Accuracy: 92.6047619047619%\n",
      "Epoch 470/600 Accuracy: 92.60952380952381%\n",
      "Epoch 471/600 Accuracy: 92.61428571428571%\n",
      "Epoch 472/600 Accuracy: 92.61190476190477%\n",
      "Epoch 473/600 Accuracy: 92.62142857142858%\n",
      "Epoch 474/600 Accuracy: 92.62380952380951%\n",
      "Epoch 475/600 Accuracy: 92.62619047619047%\n",
      "Epoch 476/600 Accuracy: 92.63571428571429%\n",
      "Epoch 477/600 Accuracy: 92.64523809523808%\n",
      "Epoch 478/600 Accuracy: 92.64523809523808%\n",
      "Epoch 479/600 Accuracy: 92.65476190476191%\n",
      "Epoch 480/600 Accuracy: 92.66666666666666%\n",
      "Epoch 481/600 Accuracy: 92.66904761904762%\n",
      "Epoch 482/600 Accuracy: 92.68809523809523%\n",
      "Epoch 483/600 Accuracy: 92.7%\n",
      "Epoch 484/600 Accuracy: 92.71190476190476%\n",
      "Epoch 485/600 Accuracy: 92.72619047619047%\n",
      "Epoch 486/600 Accuracy: 92.72619047619047%\n",
      "Epoch 487/600 Accuracy: 92.74761904761904%\n",
      "Epoch 488/600 Accuracy: 92.7452380952381%\n",
      "Epoch 489/600 Accuracy: 92.75238095238095%\n",
      "Epoch 490/600 Accuracy: 92.75952380952381%\n",
      "Epoch 491/600 Accuracy: 92.76666666666667%\n",
      "Epoch 492/600 Accuracy: 92.77619047619048%\n",
      "Epoch 493/600 Accuracy: 92.78095238095239%\n",
      "Epoch 494/600 Accuracy: 92.78571428571428%\n",
      "Epoch 495/600 Accuracy: 92.79761904761905%\n",
      "Epoch 496/600 Accuracy: 92.80238095238094%\n",
      "Epoch 497/600 Accuracy: 92.80952380952381%\n",
      "Epoch 498/600 Accuracy: 92.81428571428572%\n",
      "Epoch 499/600 Accuracy: 92.81666666666666%\n",
      "Epoch 500/600 Accuracy: 92.83333333333333%\n",
      "Epoch 501/600 Accuracy: 92.83333333333333%\n",
      "Epoch 502/600 Accuracy: 92.84285714285714%\n",
      "Epoch 503/600 Accuracy: 92.84523809523809%\n",
      "Epoch 504/600 Accuracy: 92.85%\n",
      "Epoch 505/600 Accuracy: 92.85%\n",
      "Epoch 506/600 Accuracy: 92.85952380952381%\n",
      "Epoch 507/600 Accuracy: 92.85952380952381%\n",
      "Epoch 508/600 Accuracy: 92.86190476190475%\n",
      "Epoch 509/600 Accuracy: 92.86428571428571%\n",
      "Epoch 510/600 Accuracy: 92.87380952380953%\n",
      "Epoch 511/600 Accuracy: 92.87142857142857%\n",
      "Epoch 512/600 Accuracy: 92.87619047619047%\n",
      "Epoch 513/600 Accuracy: 92.87857142857143%\n",
      "Epoch 514/600 Accuracy: 92.88333333333333%\n",
      "Epoch 515/600 Accuracy: 92.88571428571429%\n",
      "Epoch 516/600 Accuracy: 92.89047619047619%\n",
      "Epoch 517/600 Accuracy: 92.89047619047619%\n",
      "Epoch 518/600 Accuracy: 92.89761904761905%\n",
      "Epoch 519/600 Accuracy: 92.8952380952381%\n",
      "Epoch 520/600 Accuracy: 92.89761904761905%\n",
      "Epoch 521/600 Accuracy: 92.90238095238095%\n",
      "Epoch 522/600 Accuracy: 92.9047619047619%\n",
      "Epoch 523/600 Accuracy: 92.91904761904762%\n",
      "Epoch 524/600 Accuracy: 92.91904761904762%\n",
      "Epoch 525/600 Accuracy: 92.92619047619047%\n",
      "Epoch 526/600 Accuracy: 92.92380952380952%\n",
      "Epoch 527/600 Accuracy: 92.92142857142856%\n",
      "Epoch 528/600 Accuracy: 92.92380952380952%\n",
      "Epoch 529/600 Accuracy: 92.92857142857143%\n",
      "Epoch 530/600 Accuracy: 92.93333333333334%\n",
      "Epoch 531/600 Accuracy: 92.94047619047619%\n",
      "Epoch 532/600 Accuracy: 92.94761904761904%\n",
      "Epoch 533/600 Accuracy: 92.95476190476191%\n",
      "Epoch 534/600 Accuracy: 92.95476190476191%\n",
      "Epoch 535/600 Accuracy: 92.96190476190476%\n",
      "Epoch 536/600 Accuracy: 92.96666666666667%\n",
      "Epoch 537/600 Accuracy: 92.97380952380952%\n",
      "Epoch 538/600 Accuracy: 92.97619047619048%\n",
      "Epoch 539/600 Accuracy: 92.97619047619048%\n",
      "Epoch 540/600 Accuracy: 92.98095238095239%\n",
      "Epoch 541/600 Accuracy: 92.98095238095239%\n",
      "Epoch 542/600 Accuracy: 92.9952380952381%\n",
      "Epoch 543/600 Accuracy: 92.99285714285715%\n",
      "Epoch 544/600 Accuracy: 93.00714285714285%\n",
      "Epoch 545/600 Accuracy: 93.0047619047619%\n",
      "Epoch 546/600 Accuracy: 93.00714285714285%\n",
      "Epoch 547/600 Accuracy: 93.0047619047619%\n",
      "Epoch 548/600 Accuracy: 93.01904761904763%\n",
      "Epoch 549/600 Accuracy: 93.01666666666667%\n",
      "Epoch 550/600 Accuracy: 93.02142857142857%\n",
      "Epoch 551/600 Accuracy: 93.03095238095239%\n",
      "Epoch 552/600 Accuracy: 93.03333333333333%\n",
      "Epoch 553/600 Accuracy: 93.03095238095239%\n",
      "Epoch 554/600 Accuracy: 93.03571428571429%\n",
      "Epoch 555/600 Accuracy: 93.03333333333333%\n",
      "Epoch 556/600 Accuracy: 93.0404761904762%\n",
      "Epoch 557/600 Accuracy: 93.0404761904762%\n",
      "Epoch 558/600 Accuracy: 93.04761904761905%\n",
      "Epoch 559/600 Accuracy: 93.05%\n",
      "Epoch 560/600 Accuracy: 93.05238095238096%\n",
      "Epoch 561/600 Accuracy: 93.04523809523809%\n",
      "Epoch 562/600 Accuracy: 93.06190476190476%\n",
      "Epoch 563/600 Accuracy: 93.06190476190476%\n",
      "Epoch 564/600 Accuracy: 93.07857142857144%\n",
      "Epoch 565/600 Accuracy: 93.05952380952381%\n",
      "Epoch 566/600 Accuracy: 93.07619047619048%\n",
      "Epoch 567/600 Accuracy: 93.05238095238096%\n",
      "Epoch 568/600 Accuracy: 93.07380952380953%\n",
      "Epoch 569/600 Accuracy: 93.06428571428572%\n",
      "Epoch 570/600 Accuracy: 93.08571428571429%\n",
      "Epoch 571/600 Accuracy: 93.07619047619048%\n",
      "Epoch 572/600 Accuracy: 93.0904761904762%\n",
      "Epoch 573/600 Accuracy: 93.08333333333333%\n",
      "Epoch 574/600 Accuracy: 93.0904761904762%\n",
      "Epoch 575/600 Accuracy: 93.09285714285714%\n",
      "Epoch 576/600 Accuracy: 93.08571428571429%\n",
      "Epoch 577/600 Accuracy: 93.0904761904762%\n",
      "Epoch 578/600 Accuracy: 93.06904761904762%\n",
      "Epoch 579/600 Accuracy: 93.09285714285714%\n",
      "Epoch 580/600 Accuracy: 93.01428571428572%\n",
      "Epoch 581/600 Accuracy: 93.07380952380953%\n",
      "Epoch 582/600 Accuracy: 93.02857142857142%\n",
      "Epoch 583/600 Accuracy: 93.0404761904762%\n",
      "Epoch 584/600 Accuracy: 93.00714285714285%\n",
      "Epoch 585/600 Accuracy: 92.95238095238095%\n",
      "Epoch 586/600 Accuracy: 92.92142857142856%\n",
      "Epoch 587/600 Accuracy: 92.85238095238095%\n",
      "Epoch 588/600 Accuracy: 92.82619047619048%\n",
      "Epoch 589/600 Accuracy: 92.66428571428571%\n",
      "Epoch 590/600 Accuracy: 92.65476190476191%\n",
      "Epoch 591/600 Accuracy: 92.25714285714287%\n",
      "Epoch 592/600 Accuracy: 92.35952380952381%\n",
      "Epoch 593/600 Accuracy: 91.39047619047619%\n",
      "Epoch 594/600 Accuracy: 91.79285714285714%\n",
      "Epoch 595/600 Accuracy: 90.00238095238096%\n",
      "Epoch 596/600 Accuracy: 90.79523809523809%\n",
      "Epoch 597/600 Accuracy: 87.64999999999999%\n",
      "Epoch 598/600 Accuracy: 89.02380952380953%\n",
      "Epoch 599/600 Accuracy: 81.12619047619047%\n",
      "Epoch 600/600 Accuracy: 88.99761904761905%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "\n",
    "path = \"/kaggle/input/digit-recognizer/train.csv\"\n",
    "data = pd.read_csv(path, engine='c')\n",
    "label_1 = data['label']\n",
    "label_1 = label_1.T\n",
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "train_data = data[0:m].T\n",
    "X_train = train_data[1:n]\n",
    "X_train = X_train/255.0\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, input_dim=784, output_dim=10):\n",
    "        self.num_neurons = 512\n",
    "\n",
    "        self.w_1 = np.random.randn(self.num_neurons,784) * np.sqrt(2./input_dim)\n",
    "        self.w_2 = np.random.randn(10,self.num_neurons) * np.sqrt(2./10)\n",
    "        self.b_1 = np.zeros((self.num_neurons, 1))\n",
    "        self.b_2 = np.zeros((output_dim, 1))\n",
    "\n",
    "        self.learning_rate = 0.000156\n",
    "        self.alpha = 0.1\n",
    "        self.epochs = 600\n",
    "        \n",
    "#Kaiming initialization\n",
    "    def sigmoid(self,x):\n",
    "        return sci.special.expit(x)\n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        return np.where(x > 0, 1.0, 0.0)\n",
    "\n",
    "    def ELU(self, x):\n",
    "        return np.where(x >= 0.0, x, self.alpha * (np.exp(x) - 1))\n",
    "\n",
    "    def ELU_deriv(self,x):\n",
    "        return np.where(x >= 0, 1, self.alpha * np.exp(x))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        e_z = np.exp(z-np.max(z))\n",
    "        return sci.special.softmax(e_z)\n",
    "    \n",
    "    def softmax_backward(self,z):\n",
    "        do_dz = self.softmax(1-self.softmax)\n",
    "        \n",
    "    \n",
    "#Defining a set of activation functions for the convenience of changing act. functions below\n",
    "\n",
    "\n",
    "    def Forward(self, X_train):\n",
    "        self.sum_1 = np.dot(self.w_1, X_train) + self.b_1\n",
    "        self.output_1 = self.sigmoid(self.sum_1)\n",
    "        #First layer, using ReLU as activation\n",
    "\n",
    "        self.sum_2 = np.dot(self.w_2, self.output_1) + self.b_2\n",
    "        self.output_2 = self.sigmoid(self.sum_2)\n",
    "        #Second Layer, using softmax as activation\n",
    "\n",
    "        self.predictions = np.argmax(self.output_2, axis=0)\n",
    "        return self.predictions\n",
    "        #Backward Propagation\n",
    "        \n",
    "    def Backward(self, label_1, X_train):\n",
    "        \n",
    "        one_hot_labels = np.eye(10)[label_1].T\n",
    "        self.error = self.output_2 - one_hot_labels\n",
    "        self.delta_2 = self.error*self.sigmoid_derivative(self.output_2)\n",
    "        self.d_w_2 = np.dot(self.delta_2, self.output_1.T)\n",
    "        self.d_b_2 = np.sum(self.delta_2, axis=1, keepdims=True)\n",
    "        \n",
    "        self.delta_1 = np.dot(self.w_2.T, self.delta_2) * self.sigmoid_derivative(self.output_1)\n",
    "        self.d_w_1 = np.dot(self.delta_1, X_train.T)\n",
    "        self.d_b_1 = np.sum(self.delta_1, axis=1, keepdims=True)\n",
    "\n",
    "#First Layer\n",
    "\n",
    "    def update_params(self):\n",
    "        self.w_1 -= self.learning_rate * self.d_w_1\n",
    "        self.w_2 -= self.learning_rate * self.d_w_2\n",
    "        self.b_1 -= self.learning_rate * self.d_b_1\n",
    "        self.b_2 -= self.learning_rate * self.d_b_2\n",
    "#Updating parameters\n",
    "\n",
    "        return self.w_1,self.w_2,self.b_1,self.b_2\n",
    "\n",
    "    def compute_accuracy(self, label_1):\n",
    "        correct_predictions = np.sum(self.predictions == label_1)\n",
    "        total_predictions = self.predictions.shape[0]\n",
    "        self.accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    def fit(self, X_train, label_1):\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.Forward(X_train)\n",
    "            self.Backward(label_1, X_train)\n",
    "            self.update_params()\n",
    "            self.compute_accuracy(label_1)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs} Accuracy: {self.accuracy * 100}%\")\n",
    "\n",
    "# Create an instance of the Model class\n",
    "model = Model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, label_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b014c",
   "metadata": {
    "papermill": {
     "duration": 0.044182,
     "end_time": "2024-02-05T07:47:46.903537",
     "exception": false,
     "start_time": "2024-02-05T07:47:46.859355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    },
    {
     "datasetId": 19,
     "sourceId": 420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1532.607563,
   "end_time": "2024-02-05T07:47:47.671852",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-05T07:22:15.064289",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
